1
00:00:06,420 --> 00:00:08,730


2
00:00:18,000 --> 00:00:20,670
先看明白我自己的很久没有大家好

3
00:00:20,790 --> 00:00:25,710
今天我们主要讲一下泰迪b日常使用过程中的常见问题

4
00:00:25,890 --> 00:00:28,440
以及怎么定位和处理这些问题？

5
00:00:32,760 --> 00:00:35,760
然后我下午如果是那个

6
00:00:35,790 --> 00:00:41,100
呃，社区生态这边的这边主要是支持用户的一些工作已经

7
00:00:41,105 --> 00:00:43,110
负责一些开发哪些内容？

8
00:00:44,220 --> 00:00:47,910
啊，然后我们现在开始我们课程的一个主题

9
00:00:48,150 --> 00:00:53,460
而我们课程是有一个背景，就是说啊，太低地本身是一个分布式

10
00:00:53,465 --> 00:00:55,620
这个的确相对来说

11
00:00:55,710 --> 00:01:00,510
从架构和原理上都比较复杂，用户在使用的过程中

12
00:01:00,720 --> 00:01:05,910
会遇到很多的问题，呃，当然也包括原理上了，这包括加过他们

13
00:01:06,930 --> 00:01:09,990
然后我们这次课程主要就是来解决这些问题

14
00:01:10,560 --> 00:01:15,720
然后我们这次的学习目标是我们了解在使用开发的过程中

15
00:01:15,750 --> 00:01:17,580
常见的问题有哪些？

16
00:01:17,670 --> 00:01:21,030
怎么分怎么分辨这些问题是正常现象？

17
00:01:21,300 --> 00:01:26,610
因为分布式集群里面会有各种各样的调度，然后节点之间的通信的呢？

18
00:01:26,940 --> 00:01:31,980
而有一些可能大家看到一些告警，实际是属于一个正常的现象

19
00:01:32,250 --> 00:01:36,840
然后还有就是说我们碰到假如说真的碰到一些

20
00:01:36,990 --> 00:01:38,700
影响集权

21
00:01:38,705 --> 00:01:41,910
正常运行，或者说是影响业务的一些问题

22
00:01:42,000 --> 00:01:45,090
怎么来定位？怎么来处理这些问题？

23
00:01:46,140 --> 00:01:50,430
然后我们这次主要的知识点是

24
00:01:50,490 --> 00:01:54,420
呃，发向是比较大，然后一个是读热点

25
00:01:55,110 --> 00:01:58,860
因为是写热点啊，还有就是术冲突慢查询

26
00:01:59,130 --> 00:02:01,710
然后当然这些都是跟业务上相关的

27
00:02:01,740 --> 00:02:03,600
然后还有就是说我们

28
00:02:03,660 --> 00:02:08,340
呃，我们多个组件上有组件是分布式集群组件比较多

29
00:02:08,460 --> 00:02:13,770
然后呢，我们重点还有一个重点是看一下各个组件上面的一些

30
00:02:13,775 --> 00:02:15,180
常见的人的信息

31
00:02:15,240 --> 00:02:16,440
然后就是我们

32
00:02:16,445 --> 00:02:17,700
还有一个

33
00:02:17,850 --> 00:02:21,600
监控算是一个比较和谐的组件，然后

34
00:02:21,960 --> 00:02:26,790
在使用的过程，再使用它的这个的过程中，我们经常需要通过监控

35
00:02:26,880 --> 00:02:28,950
来定位和排查一些问题

36
00:02:29,580 --> 00:02:30,270
啊？

37
00:02:31,380 --> 00:02:33,960
然后第一部分我们先说一下

38
00:02:34,560 --> 00:02:38,370
比较大的四个场景，就是斜着点读热点

39
00:02:38,430 --> 00:02:40,560
但是，热点里面是

40
00:02:40,620 --> 00:02:45,930
呃，我是稍微细分了一下，这里是分了一个小婊读者两个亿

41
00:02:45,935 --> 00:02:46,920
这个多多了点

42
00:02:47,100 --> 00:02:48,630
小婊多少年？

43
00:02:49,170 --> 00:02:54,480
这个主要是说可能有一些用户把数据或者说是吧？

44
00:02:54,485 --> 00:02:57,600
业务切换切换台登记上面

45
00:02:57,605 --> 00:03:01,860
但是呢，可能有一些数据可能有一些表或者说是酷

46
00:03:01,865 --> 00:03:04,560
是相对来说数据量是比较小

47
00:03:04,830 --> 00:03:06,180
他这样的话

48
00:03:06,600 --> 00:03:11,460
这些数据可能是只跟不到某一个节点，或者说是少数几个节点

49
00:03:11,465 --> 00:03:16,770
这个时候当当有一个比较平常的产品，或者说是诸如此类这些

50
00:03:16,775 --> 00:03:17,670
就过来

51
00:03:17,700 --> 00:03:19,920
然后就会发现这些

52
00:03:20,100 --> 00:03:25,320
业务呢？然后压力全都是集中在几个节点上，这个时候就出现一个读热点

53
00:03:25,530 --> 00:03:27,240
想要的多了点

54
00:03:27,270 --> 00:03:28,770
然后还有业务多了呢

55
00:03:28,775 --> 00:03:30,870
业务组热点主要

56
00:03:30,875 --> 00:03:32,040
发生在

57
00:03:32,700 --> 00:03:38,010
比如说一些呃日志归档的一些业务，你可能是需要长一段

58
00:03:38,550 --> 00:03:40,380
时间区间的一个数据

59
00:03:40,385 --> 00:03:45,690
然后这个时候，然后再加上这个数据可能在集群里面试卷是？

60
00:03:47,610 --> 00:03:52,110
看一个区间来分布的，然后这个时候你可能查到的数据是？

61
00:03:52,115 --> 00:03:57,420
做到某一个台词杯上，或者说是少数几个，还是约上，然后也可能是也可能是产生一个

62
00:03:57,425 --> 00:03:58,110
热点

63
00:03:59,430 --> 00:04:03,210
然后读写热点都是有一个问题，就是说

64
00:04:03,600 --> 00:04:08,190
不能发货，不能发挥出分布式的一个优势，只是说

65
00:04:08,550 --> 00:04:12,600
少数的节点，然后可能压力很大，到了一个瓶颈

66
00:04:13,230 --> 00:04:15,960
然后这个时候呢，就是出现了一个木桶效应

67
00:04:16,410 --> 00:04:19,410
然后再往下，第三个是受冲突

68
00:04:19,470 --> 00:04:24,780
而冲突就是大家在使用数据库的过程中呢？实际上碰到的也挺多的

69
00:04:25,740 --> 00:04:31,050
啊，一个是跟业务相关，还有一个就是跟15模型是也是有关系的

70
00:04:31,890 --> 00:04:34,320
孩子就说跟我的

71
00:04:34,530 --> 00:04:38,790
呃，是悲观锁还是说是乐观锁都是有些

72
00:04:38,820 --> 00:04:39,690
相关

73
00:04:39,900 --> 00:04:44,790
然后一旦发生了事冲突，可能可能在业务上

74
00:04:44,850 --> 00:04:50,160
呃，会产生一些比较明显的比较明显的一些现象，比如说是

75
00:04:50,280 --> 00:04:52,140
呃曼插曲

76
00:04:52,260 --> 00:04:54,480
比如说是啊

77
00:04:54,630 --> 00:04:58,830
因为因为发生了食物冲突之后，他的城市会比较多

78
00:04:58,860 --> 00:05:01,260
然后对整个集群的负载

79
00:05:01,680 --> 00:05:05,610
然后整个基础的一些CPU，运行内存的压力都会比较大

80
00:05:06,480 --> 00:05:09,090
然后还要卖他选卖茶选

81
00:05:09,210 --> 00:05:11,400
可能是有前面的

82
00:05:11,460 --> 00:05:16,770
三个场景导致的也有可能是烧烤本身，或者说是走错了，所以

83
00:05:16,950 --> 00:05:18,090
或者说是

84
00:05:18,095 --> 00:05:20,070
啊，这个烧烤本身就是

85
00:05:20,220 --> 00:05:21,240
啊？

86
00:05:21,720 --> 00:05:24,960
消耗资源比较多，或者是少数据比较大

87
00:05:25,260 --> 00:05:27,300
然后都可能会产生有办法去

88
00:05:28,020 --> 00:05:29,850
好，然后我们继续往下

89
00:05:30,360 --> 00:05:31,560
我不知道

90
00:05:31,620 --> 00:05:36,390
这次的学习目标呢，是我们针对这几个场景

91
00:05:36,690 --> 00:05:42,000
来看一下这些场景，我们怎么来规避一下？然后还有就是说讲

92
00:05:42,005 --> 00:05:44,040
比如说真的遇到了这些茶叶

93
00:05:44,340 --> 00:05:48,930
能从哪些角度来定位这些问题，然后从哪些角度来解决这些问题？

94
00:05:52,590 --> 00:05:56,100
我们先说我们先说写了点

95
00:05:56,105 --> 00:06:00,090
写热点啊，这个是放到第一个是因为？

96
00:06:00,360 --> 00:06:05,400
不管你是后面的读热点，还是说呃一些

97
00:06:06,000 --> 00:06:11,310
比如说啊，事物冲突啊之类的都跟你写你写进数据库里

98
00:06:11,315 --> 00:06:12,870
的数据是有关系的

99
00:06:13,020 --> 00:06:17,940
啊，那我们这里就先从数据的一个入口来说

100
00:06:18,690 --> 00:06:24,000
好，然后我们这里面呢，因为我们这次的课程主要是一个

101
00:06:24,005 --> 00:06:27,840
问题的一个副线和一个解决的一个

102
00:06:27,845 --> 00:06:28,680
喝茶了

103
00:06:28,740 --> 00:06:32,340
所以呢，我们这边是需要对这个问题做一个副线

104
00:06:32,790 --> 00:06:38,100
然后我们这里呢？为了简便体现我们是使用随着奔驰来模拟这个写着点条件

105
00:06:39,570 --> 00:06:41,100
然后

106
00:06:41,370 --> 00:06:44,760
要提到写字点的话，我们首先需要知道

107
00:06:44,910 --> 00:06:48,210
数据在我们她的心里面是怎么存的？

108
00:06:48,600 --> 00:06:53,520
也就是说，大家需要对整个泰迪背的一个架构是需要有一定的了解

109
00:06:54,060 --> 00:06:59,370
啊，然后大家呢？首先是已经知道了啊，我们态对比

110
00:06:59,375 --> 00:07:02,760
核心组件主要分成三个是霹雳

111
00:07:02,790 --> 00:07:07,350
还可以，可以和泰迪b好像那数据是存在哪儿呢？

112
00:07:08,520 --> 00:07:12,870
啊，我们数据是在KTV里面被d呢？他只是做一个调度

113
00:07:13,080 --> 00:07:18,390
就是说霹雳他们知道你每个台词说上面好，你每个月都背上面有多少？

114
00:07:18,395 --> 00:07:20,250
这个离得有多少个位置？

115
00:07:20,255 --> 00:07:25,470
哪个数据也是在哪儿？她的微商她是知道这么一个信息，然后他的秘密

116
00:07:25,980 --> 00:07:27,360
她主要是

117
00:07:27,600 --> 00:07:32,730
你可以把它理解为是一个买烧烤，他是来解析你的

118
00:07:32,735 --> 00:07:36,150
从业务端或者是从后端这边过来的思考

119
00:07:36,270 --> 00:07:37,230
然后

120
00:07:37,235 --> 00:07:42,540
啊，这些解析出来的烧烤，然后他再根据这些深刻的请求去

121
00:07:42,930 --> 00:07:48,090
最硬的它可以里面去对这些数据做一些查询或者说是做一些

122
00:07:48,150 --> 00:07:50,640
比如说一些计算之类的

123
00:07:52,410 --> 00:07:57,720
那我们这里呢？数据只要是主要是存到TK v里面的啊，所以我们的

124
00:07:57,810 --> 00:08:00,480
写热点的，主要也是翻开那个BB b

125
00:08:01,140 --> 00:08:06,450
好，然后我们再需要了解一下，就是写热点，他对整个基础

126
00:08:06,750 --> 00:08:10,950
会有什么影响，或者说是对整个业务会有什么影响？

127
00:08:11,250 --> 00:08:16,560
然后还有就是说我们怎么来规避这个？写着点不知道怎么解决写着点

128
00:08:17,550 --> 00:08:20,490
假如说我们业务上已经是这样了

129
00:08:21,300 --> 00:08:24,330
已经是有了些热点了，好，那我们怎么来解决？

130
00:08:25,200 --> 00:08:29,970
哎呀，最后一个就是在他的必中，有没有有没有什么比较？

131
00:08:30,090 --> 00:08:35,280
呃特有的一些方式来规避这个斜着点，或者说是说来解决这么斜着点

132
00:08:36,180 --> 00:08:39,060
那我们下面就开始进入写热点的一个整体

133
00:08:40,110 --> 00:08:45,420
好，我们因为使用新的问题来模拟的啊，这里是给了一个比较简单的一个

134
00:08:45,425 --> 00:08:46,110
配置

135
00:08:46,920 --> 00:08:49,890
然后我们这个配置呢？大体的意思就是说

136
00:08:49,920 --> 00:08:51,330
我们是

137
00:08:51,480 --> 00:08:56,790
用c的问题去加一个裤，就是SB探测仪这个裤，然后这个父母6000

138
00:08:56,795 --> 00:08:57,870
江南是

139
00:08:57,930 --> 00:09:00,720
时间相对要长一点，然后

140
00:09:00,725 --> 00:09:02,460
就是说不准的超市

141
00:09:02,910 --> 00:09:07,530
呃，不是说我们还还没有生产出来呢？然后就这样感冒可以

142
00:09:08,160 --> 00:09:10,080
然后损害的这个是

143
00:09:10,530 --> 00:09:12,780
我们这边是写了32

144
00:09:13,020 --> 00:09:18,150
然后大家可以根据自己的机器的配置调高，或者说是调低

145
00:09:22,410 --> 00:09:26,490
然后我们这边模拟的是一个没有索引的表

146
00:09:26,550 --> 00:09:29,910
好，这里就有有一个

147
00:09:30,540 --> 00:09:34,260
有一个理论的一个知识吧，就是说

148
00:09:34,740 --> 00:09:38,310
我们为什么要使用一个没有所以呢，表达式

149
00:09:38,910 --> 00:09:41,160
就是说大家可以看一下我们

150
00:09:41,165 --> 00:09:43,260
官网上有一些tak v

151
00:09:43,920 --> 00:09:47,490
数据存储的一个逻辑的一个

152
00:09:47,730 --> 00:09:49,200
原理对

153
00:09:49,290 --> 00:09:53,400
当他特别写数据的时候，她在他在里面是

154
00:09:53,760 --> 00:09:54,900
怎么存的？

155
00:09:55,830 --> 00:10:00,150
就是说它在蹲的时候，数据和索引，实际上是

156
00:10:00,540 --> 00:10:03,930
用不同的方式去承担啊，那我们这里呢？

157
00:10:04,380 --> 00:10:09,690
创建一个模拟一个没有索引的表是规避的索引数据的一个

158
00:10:09,780 --> 00:10:10,770
停下

159
00:10:11,070 --> 00:10:12,210
是这样的

160
00:10:13,950 --> 00:10:19,260
然后我们这边是创建了一个裤子最变态的，一然后又创建了一个表

161
00:10:19,265 --> 00:10:24,570
自己的探测也是艾滋病太可一然后当然这里的库和表的名字就是说

162
00:10:24,750 --> 00:10:25,980
根据

163
00:10:26,310 --> 00:10:30,000
这是奔驰它一个默认的一个值来做的啊！

164
00:10:30,510 --> 00:10:34,320
我们下面呢，是一个表结构，这个表结构呢？实验也是

165
00:10:34,740 --> 00:10:40,050
时间也是黑的，奔驰就是啊，出太阳了然后我说是这些玩具被他

166
00:10:40,055 --> 00:10:41,430
问，生产的一个表

167
00:10:41,490 --> 00:10:42,720
他这里的我们

168
00:10:42,780 --> 00:10:45,690
我们把这个表上的一个二级作业给去掉了

169
00:10:47,310 --> 00:10:48,030
对

170
00:10:51,390 --> 00:10:52,110
好

171
00:10:52,170 --> 00:10:55,560
然后最后一条呢，是一个嗯

172
00:10:56,100 --> 00:11:00,180
随着问题的一个命令，然后这个命令呢？我们只是用它来写入

173
00:11:00,870 --> 00:11:06,180
只是应该写写入做一个邪恶操作，因为我们前面是已经手动穿着这个

174
00:11:06,570 --> 00:11:07,710
服务

175
00:11:07,800 --> 00:11:13,110
已经穿戴好了，所以我们下面直接可以开始模拟这个邪恶操作，然后我们这边

176
00:11:13,115 --> 00:11:17,190
模拟的时候呢，是写的就大家可以发现我们写的是一个表

177
00:11:17,370 --> 00:11:20,250
而且这个贴出赛程设置的是长大

178
00:11:20,790 --> 00:11:26,040
对然后因为是写一个写一个表的时候，然后才能

179
00:11:26,190 --> 00:11:29,730
就是数据在KTV里面的分布是跟

180
00:11:29,880 --> 00:11:31,770
讲的ID和

181
00:11:32,370 --> 00:11:37,140
逐渐的ID，等等这些东西是相关的，所以说我们只模拟

182
00:11:37,620 --> 00:11:41,220
只模拟一个表，然后比较容易发展出这个

183
00:11:41,280 --> 00:11:42,960
写写着点的一个现象

184
00:11:43,680 --> 00:11:48,990
啊，然后这个退回去给我们设备设置的事比较大嗯，因为设置比较小的时候你

185
00:11:48,995 --> 00:11:50,010
可能是

186
00:11:50,130 --> 00:11:52,770
他还没有复现出这个现象，或者说是

187
00:11:52,830 --> 00:11:53,730
啊还？

188
00:11:53,850 --> 00:11:58,050
或者说是简简单复检出来了，但是还不太能说明问题

189
00:11:58,230 --> 00:12:03,540
然后啊，然后就导致这个数据也写完了然后去呃

190
00:12:03,545 --> 00:12:06,960
还好，所以说我们这边设置数据量比较大一点

191
00:12:08,250 --> 00:12:09,030
啊？

192
00:12:11,010 --> 00:12:16,320
然后我们下面呢是来看一下，就是我们根据前面的这个

193
00:12:16,325 --> 00:12:18,450
随着奔驰压缩的一个结果

194
00:12:18,600 --> 00:12:23,910
写入数据的一个结果能看出我们在写作过程中，然后监控上面

195
00:12:23,915 --> 00:12:25,650
一些变化

196
00:12:25,800 --> 00:12:28,560
而这个监控就是指我们前面说的

197
00:12:28,770 --> 00:12:31,890
呃，我们的其中一个组件就是

198
00:12:31,920 --> 00:12:35,100
呃，普罗米修斯格尔的呢？这个监控的组件

199
00:12:36,510 --> 00:12:41,640
啊，然后我们这里面呢，主要看一下批地的监控

200
00:12:41,700 --> 00:12:45,180
然后当然从其他的监控上面也能看出这个现象

201
00:12:45,420 --> 00:12:48,060
对，因为pd他是一个

202
00:12:48,090 --> 00:12:52,230
可以理解为是一个管理的一个节点，他们知道你

203
00:12:52,410 --> 00:12:54,330
整个激情的一个

204
00:12:54,570 --> 00:12:58,650
状态就是各个节点的写字状态，读的状态，他都可以知道

205
00:12:59,250 --> 00:13:04,560
对，当然他拿到了，拿到这个信息呢，是一个相对一个之后的一个

206
00:13:04,565 --> 00:13:05,190
结果

207
00:13:05,820 --> 00:13:09,090
然后我们从这个监控上面呢，它有一个好处来的

208
00:13:09,300 --> 00:13:10,410
有一个

209
00:13:10,560 --> 00:13:12,420
啊，这么一个监控下

210
00:13:12,480 --> 00:13:14,640
然后他的意思是指

211
00:13:15,360 --> 00:13:17,640
展示出在你

212
00:13:18,150 --> 00:13:22,980
在你单位时间写入的时候，然后每一个taka上面

213
00:13:22,985 --> 00:13:23,940
谢

214
00:13:23,970 --> 00:13:26,940
就显得热点的厉害的一个数量

215
00:13:27,180 --> 00:13:30,180
对然后这个粒子数量低的的一个

216
00:13:30,210 --> 00:13:35,520
对这理解的一个概念呢？大家可以看一下前面的一些课程，然后是有一些讲解

217
00:13:37,320 --> 00:13:39,390
然后我们这个监控里面可以看到

218
00:13:39,395 --> 00:13:42,090
啊，我这个在写的过程中呢？

219
00:13:42,095 --> 00:13:45,480
然后一直是有一个瑞典是

220
00:13:46,350 --> 00:13:49,980
数量11，然后其他的是零，然后当然我们

221
00:13:49,985 --> 00:13:55,290
也可以看到这个场有一个死到一这个食堂意在某某一个时间，他是有一个

222
00:13:55,710 --> 00:14:01,020
有一个小刀，丰满是有一个一的直我这个实际上可以忽略是

223
00:14:01,050 --> 00:14:03,060
只是只是一个

224
00:14:03,360 --> 00:14:04,410
啊？

225
00:14:04,830 --> 00:14:06,960
相当于是一个讽刺的对

226
00:14:07,290 --> 00:14:12,600
然后这个从这个监控上面来分析的话，我们可以看到啊，我们这个热

227
00:14:12,605 --> 00:14:15,930
点主要写热点主要集中在小市场

228
00:14:15,990 --> 00:14:21,300
那假如说我们这个机器有三个才可以买，就是五个，或者说是七个

229
00:14:21,305 --> 00:14:22,290
等等等

230
00:14:23,010 --> 00:14:27,360
当然不一定是奇数，也可以是偶数的，只要是大于数码数就可以了

231
00:14:27,630 --> 00:14:30,510
那这个时候呢，我们就可以看到

232
00:14:31,680 --> 00:14:36,960
写的压力全都集中在了kv 4上面，这个死道四就是这台kv

233
00:14:37,110 --> 00:14:42,420
就是只其中一个台词背这个四只是有pp分配给他配备一个ID

234
00:14:43,590 --> 00:14:48,570
啊啊的压力全都集中在这个阶段上，那其他节点全都是空闲的

235
00:14:48,575 --> 00:14:52,440
所以就会产生内幕总效应，当这个压力特别大的时候

236
00:14:52,620 --> 00:14:54,540
这个节目就是为了一个瓶颈

237
00:14:54,690 --> 00:15:00,000
然后也会影响其它的业务，比如说其他的表达一些写入其他表的西安城

238
00:15:00,005 --> 00:15:01,080
查询等等

239
00:15:01,110 --> 00:15:02,310
都会有些

240
00:15:02,315 --> 00:15:03,930
同成都的一些影响

241
00:15:06,090 --> 00:15:08,730
啊，那我们怎么闺蜜写热点呢？

242
00:15:09,390 --> 00:15:13,680
这些热点产生的一个原因是因为我们

243
00:15:13,920 --> 00:15:18,450
经常就是说，在使用MySQL的时候是有一个

244
00:15:18,600 --> 00:15:23,910
习惯就是说我们经常会给表加一个int类型的逐渐，并且是自己

245
00:15:23,915 --> 00:15:24,660
是的

246
00:15:24,870 --> 00:15:30,180
那这个时候呢，在她的逼里面，因为数据存储，它是有一个格式的

247
00:15:31,170 --> 00:15:32,070
当

248
00:15:32,220 --> 00:15:33,300
当你

249
00:15:33,305 --> 00:15:38,070
就是假如说有一个表，并且有一个印度历史逐渐，而且还是自动的

250
00:15:38,430 --> 00:15:43,740
好，那这个时候呢？因为嗯，就是说在k在

251
00:15:43,745 --> 00:15:47,130
KTV里面数据存储的时候，它是有一个他的ID的

252
00:15:47,190 --> 00:15:50,400
就是在QQ里面，它本质是一个kv的存储

253
00:15:50,760 --> 00:15:55,860
他的k里面就包含了一个汗蒸it的这么一个阶段，当你

254
00:15:56,400 --> 00:16:01,710
当你的表结构是int类型是由int类型的底线的时候，这个孩子ID就等于

255
00:16:01,715 --> 00:16:02,970
主键的值

256
00:16:05,160 --> 00:16:07,560
那这个时候呢，假如说

257
00:16:07,590 --> 00:16:11,130
主键是自增的，也就是说汉的ID也是自增的

258
00:16:11,790 --> 00:16:13,170
而且呢？

259
00:16:13,710 --> 00:16:19,020
而且呢，我们在kt里面是有一个睿智的感觉，这个睿智就是按

260
00:16:19,260 --> 00:16:24,570
佩的一个范围来划分的啊，那你这个时候呢，你去写入的时候

261
00:16:25,530 --> 00:16:30,840
每一次写的都是相对靠后的，是相对靠后写的是

262
00:16:30,845 --> 00:16:32,280
就最后一个危险

263
00:16:32,340 --> 00:16:35,010
就是说假如说你啊！

264
00:16:35,070 --> 00:16:36,300
就一个表

265
00:16:36,420 --> 00:16:37,140
啊？

266
00:16:37,145 --> 00:16:42,450
当然也是说有主见，这件事自动ID的好，那些1000万数据那你写到九题写了

267
00:16:42,455 --> 00:16:46,980
900万的时候，他写的是最后几个的，也是写了最后的一个人展

268
00:16:47,070 --> 00:16:52,380
把你写了1000万的时候，讲说他分裂了，分裂之后呢？你依旧写的是最后

269
00:16:52,385 --> 00:16:53,220
也不知道

270
00:16:53,250 --> 00:16:55,650
他这个时候呢，就是说不管这个瑞典

271
00:16:56,850 --> 00:17:01,890
就是不管这个睿智的力量，他在哪个节点上？那这个节点他可能就是一个热点

272
00:17:02,070 --> 00:17:03,390
是闲着点

273
00:17:03,480 --> 00:17:04,560
好

274
00:17:04,980 --> 00:17:10,290
那这个时候呢，我们是啊，在她的b上面是有一个参数可以

275
00:17:10,295 --> 00:17:11,850
打算这个协调点

276
00:17:12,360 --> 00:17:17,250
他们怎么来打伞的啊？我们就是啊，下面具体看一下

277
00:17:17,370 --> 00:17:20,970
然后我们依旧适用其实奔驰的模拟

278
00:17:21,780 --> 00:17:26,850
我们这边就是为了跟前面保持一个一次线，还是用一个表？

279
00:17:27,030 --> 00:17:29,160
然后我们这边是用的SB

280
00:17:29,310 --> 00:17:34,170
拍了三二这个裤，然后线，然后上面我们已经出线了

281
00:17:34,530 --> 00:17:39,840
写这点是怎么样的一个场景啊？那我们怎么来规避这个写着点吧？

282
00:17:39,845 --> 00:17:42,360
大家首先需要知道一个

283
00:17:42,780 --> 00:17:47,550
原理就是说数据在KTV里面是怎么存储的？

284
00:17:47,700 --> 00:17:53,010
然后我们大家已经知道，就是说在kv里面数据本质的存储实验

285
00:17:53,015 --> 00:17:56,250
是kv的格式就是k80的格式

286
00:17:56,400 --> 00:17:57,810
啊然后？

287
00:17:58,380 --> 00:18:01,890
然后呢，kay ta里面包含了一个他的ID

288
00:18:01,950 --> 00:18:07,260
这个憨豆ID呢，就是假如说你们的没有主见，或者说是刘主见

289
00:18:07,320 --> 00:18:09,390
但是说是飞燕的类型的

290
00:18:09,450 --> 00:18:12,240
这个汉堡IDE是由系统生成的一个值

291
00:18:12,690 --> 00:18:15,780
但是当然这个商场的纸

292
00:18:15,810 --> 00:18:18,780
系统自动生成的这个值，他也是一个

293
00:18:19,020 --> 00:18:22,410
呃，算是一个自尊的，但是一个不连续的一个值

294
00:18:23,280 --> 00:18:25,140
然后假如说

295
00:18:25,380 --> 00:18:30,240
你的表结构里面有一个int类型的组件，并且是

296
00:18:30,510 --> 00:18:31,380
啊？

297
00:18:31,770 --> 00:18:36,210
就是有一个颜色类型主线的那这个时候呢，你写的数据

298
00:18:36,630 --> 00:18:39,300
里面的k就是kv里面的

299
00:18:39,660 --> 00:18:42,360
对应的key就等于这个主线的一个值

300
00:18:42,720 --> 00:18:48,030
好，那假如说我们按照买收购里面的一个使用习惯好，我们比

301
00:18:48,035 --> 00:18:48,690
掉了

302
00:18:49,080 --> 00:18:51,990
绝大多数吧，然后都是有

303
00:18:52,140 --> 00:18:57,450
并且对性组件，并且是自动的，那有那在证明一个前提下在

304
00:18:57,455 --> 00:19:00,120
可以在KTV里面写入的数据

305
00:19:00,240 --> 00:19:04,470
在对应到kv里面写入数据都是有一个

306
00:19:05,130 --> 00:19:08,070
确定了一个k的一个

307
00:19:08,250 --> 00:19:11,610
就是在k里面确定都有一个憨豆ID

308
00:19:12,240 --> 00:19:17,550
他的ID就等于那个主线的直他这个时候，但是写数据的时候，比如说你写了

309
00:19:17,555 --> 00:19:18,390
钱了

310
00:19:18,630 --> 00:19:19,770
千万的数据

311
00:19:19,775 --> 00:19:21,870
好，虽然说我们在

312
00:19:21,900 --> 00:19:26,190
呃呃呃，虽然说我们在她的b里面数据是一个分布式存储的

313
00:19:27,030 --> 00:19:29,430
但是呢，数据还是有一个

314
00:19:29,435 --> 00:19:30,990
切割的一个

315
00:19:31,530 --> 00:19:32,460
啊？

316
00:19:32,910 --> 00:19:38,220
原理就是说我们数据都是根据按润景就是按范围来夸

317
00:19:38,225 --> 00:19:40,290
看了很多个睿智

318
00:19:40,980 --> 00:19:43,500
他每个月着呢都带都是

319
00:19:44,610 --> 00:19:46,320
最近的一个

320
00:19:46,560 --> 00:19:49,080
对应了一个憨豆还低的一个范围

321
00:19:49,140 --> 00:19:50,910
他这个时候呢，当你

322
00:19:51,000 --> 00:19:56,310
是当你比如说呃呃呃有个主见，然后数据都是自动来写的

323
00:19:56,315 --> 00:20:00,000
那这个时候呢，就是不管是微卷有多少个？

324
00:20:00,005 --> 00:20:02,400
看你每一次写的时候都是写的

325
00:20:02,700 --> 00:20:06,960
就是他因为你是智障嘛，ID，会越来越大了，直接会越来越大

326
00:20:07,050 --> 00:20:10,470
那你每一次写的时候都是写的最后的一个微博

327
00:20:10,860 --> 00:20:16,170
那这个时候呢，就是说你这个睿智的李导在哪个节点上那么那？

328
00:20:16,380 --> 00:20:19,920
最近的这个节点，然后就会有一个写了一个热点

329
00:20:20,430 --> 00:20:21,780
然后所以

330
00:20:22,290 --> 00:20:26,220
所以呢，我们建议就是在

331
00:20:26,225 --> 00:20:27,960
将是将业务

332
00:20:27,990 --> 00:20:29,550
或者说是将数据

333
00:20:29,580 --> 00:20:31,260
签到台哩哔哩

334
00:20:31,530 --> 00:20:35,970
前面我们已经复现了写热点写热点的一个场景

335
00:20:36,090 --> 00:20:41,400
啊，那我们既然有一些人将游戏而变的一个存在，那我们怎么来？

336
00:20:41,405 --> 00:20:42,780
避免这个写着点

337
00:20:42,840 --> 00:20:45,060
啊，这里我们就是

338
00:20:45,065 --> 00:20:49,500
首先讲一下数据，在它可以里面是怎么存储的？

339
00:20:50,220 --> 00:20:53,700
然后前面的课程里面，大家如果

340
00:20:53,790 --> 00:20:59,100
呃，有接触到的话可以知道，就是在KTV里面的数据本

341
00:20:59,105 --> 00:21:00,660
质上是一个

342
00:21:00,960 --> 00:21:04,560
全都是k86的一个存储的格式

343
00:21:04,710 --> 00:21:08,760
然后呢，在k16存储的格式基础上

344
00:21:08,820 --> 00:21:14,130
我们又把数据按照润纸就是按照范围给他划分了

345
00:21:14,135 --> 00:21:15,360
多个的

346
00:21:15,390 --> 00:21:16,260
没整

347
00:21:17,070 --> 00:21:22,380
好，所以这是一个大体的就是大面上的一个数据结构的一个情况

348
00:21:22,470 --> 00:21:23,160
啊？

349
00:21:23,250 --> 00:21:27,180
然后再细看的话，就是说我们每一行数据

350
00:21:27,210 --> 00:21:29,880
实际上，在QQ里面都是一个kv

351
00:21:29,910 --> 00:21:32,250
然后这个kv里面的k呢？

352
00:21:32,340 --> 00:21:35,040
还包含了一个憨豆ID的一个字段

353
00:21:36,000 --> 00:21:37,620
然后这个憨豆ID

354
00:21:38,040 --> 00:21:43,350
就是假如说你的业务上有一个表示有int类型

355
00:21:43,500 --> 00:21:48,180
的逐渐那这个时候呢？这个汉堡ID就等于这个逐渐的值

356
00:21:48,510 --> 00:21:53,820
假如说是没有主见，或者说有主见，但是这个主见是非应他的想法

357
00:21:54,210 --> 00:21:58,740
那你这个号的ID就是一个int 64位的一个

358
00:21:59,400 --> 00:22:04,710
由由CD b这个系统来生成的一个侄当然生成的这个值

359
00:22:04,715 --> 00:22:07,230
那他也是有一个资格的一个

360
00:22:07,890 --> 00:22:13,140
有一个自动的一个规律，但是这个资质呢，他不一定是连续的

361
00:22:13,380 --> 00:22:14,790
对然后

362
00:22:14,820 --> 00:22:20,130
好，那这么就是我们这样的通关沟通一下来

363
00:22:20,135 --> 00:22:23,670
有的观贯穿一下这个数据存储的一个原理的话

364
00:22:24,570 --> 00:22:29,880
然后我们这个时候就可以理解，假如说好，我们按照麦思考的习惯

365
00:22:30,240 --> 00:22:34,650
表表还是有一个逐渐并且还是自动的啊，那你写的时候

366
00:22:34,680 --> 00:22:36,900
写数据的时候在kv里面

367
00:22:37,470 --> 00:22:42,780
相当于对于k对于kt里面存储的这个k来说，数据全都是一个

368
00:22:45,270 --> 00:22:50,580
就是递增的一个写的一个方式，就是说每一次写的时候都会落到

369
00:22:52,950 --> 00:22:55,500
都会落到最后这一个睿智里面

370
00:22:55,560 --> 00:22:59,070
就是讲说你有一个空表哈，你这个空调的，然后

371
00:22:59,610 --> 00:23:04,920
他的表结构是由英特利性逐渐毕竟是自动的啊，那你比如说写1000万？

372
00:23:04,925 --> 00:23:05,670
数据

373
00:23:05,820 --> 00:23:11,130
那你在写的时候，虽然说癌症，它是有一个分裂的一个

374
00:23:11,880 --> 00:23:17,190
原理，但是呢，当你写的时候呢？这个瑞典他不管再怎么分裂？

375
00:23:17,195 --> 00:23:22,230
后面的这一个最后面这个睿智，他的区间一定是最大的一个区间

376
00:23:22,470 --> 00:23:24,150
那你在写后面

377
00:23:24,480 --> 00:23:27,690
更大的数的时候肯定是落到这个位置里面

378
00:23:27,960 --> 00:23:29,430
那你这个睿智

379
00:23:30,120 --> 00:23:35,430
那你这个睿智的壁纸，不管落到哪个才可以被上面这个才kv就成了呀？就成

380
00:23:35,435 --> 00:23:36,570
里面的一个热点

381
00:23:36,870 --> 00:23:38,340
啊，那这个时候

382
00:23:38,345 --> 00:23:40,230
有同学可能会问

383
00:23:40,560 --> 00:23:45,870
假如说我的业务上就是有一个int类型逐渐好，那这个时候我知道

384
00:23:45,875 --> 00:23:47,280
热点该怎么办？

385
00:23:47,460 --> 00:23:49,230
该怎么来解决这个热点？

386
00:23:49,740 --> 00:23:55,050
我们我们现在呢是有一个啊，不是特别优雅的

387
00:23:55,140 --> 00:23:57,750
一个办法就是对原有的

388
00:23:57,840 --> 00:24:01,230
业务吧，然后会有一个

389
00:24:01,650 --> 00:24:04,680
侵入性，就是说我们会

390
00:24:05,100 --> 00:24:10,410
就是我们会需要把这个逐渐给她取消掉，或者说把这个主

391
00:24:10,415 --> 00:24:12,690
股改成飞行的旅行的

392
00:24:13,260 --> 00:24:18,570
啊，那这个时候呢？这个憨豆ID就是kv里面，这个k TK tid

393
00:24:19,290 --> 00:24:23,220
相当于就是由系统来生产的一个值

394
00:24:23,310 --> 00:24:28,620
那既然是由系统来完成的好，我们就是有有办法可以来把他打死

395
00:24:29,370 --> 00:24:31,590
所以我们就呃

396
00:24:32,070 --> 00:24:35,490
但随着这个功能，然后产生了一个参数

397
00:24:35,790 --> 00:24:36,990
就是沙滩

398
00:24:37,170 --> 00:24:42,480
上的l yd，然后这么一个参数，那这个参数是什么意思呢？就是说我们

399
00:24:42,485 --> 00:24:46,740
前面也说了，他的ID是一个印象，就是设备的一个值

400
00:24:47,010 --> 00:24:52,320
那这个参数的意思就是说啊，比如说我这个表结构里面是设置等于

401
00:24:52,325 --> 00:24:54,900
那这个参数的意思就是说

402
00:24:55,140 --> 00:24:59,160
把int就是四位的前三位，给他做一个随机

403
00:24:59,250 --> 00:25:04,560
那这个时候，他她的ID生成的值就是因为因为前三位是

404
00:25:04,565 --> 00:25:07,890
就已经做了一个随机已经变化了啊！

405
00:25:07,895 --> 00:25:12,750
在这个时候，它自动生成的每一个焊的ID就是

406
00:25:13,050 --> 00:25:17,370
从一定程度来，从一定程度上来说，是已经打伞了

407
00:25:17,700 --> 00:25:23,010
就是说你可能你可能第一个还能ID上传到了以前，还有可能是上课的一

408
00:25:23,550 --> 00:25:28,860
然后第二个呢，你可能就成了一个99，那这个时候呢，这个数值就是

409
00:25:28,865 --> 00:25:29,790
因为是

410
00:25:30,090 --> 00:25:35,400
在在书中的前几位来做的一个变更，那这个时候呢，你得佩刀

411
00:25:35,405 --> 00:25:40,710
范围实际上就发生一个很大的变化，那这个时候你不同的相邻的数据

412
00:25:40,715 --> 00:25:45,630
数据实际上就是弱到不同的群里面，然后从而达到了一个答案效果

413
00:25:45,690 --> 00:25:48,180
然后后面还是

414
00:25:48,360 --> 00:25:53,670
依旧是我们跟上面是一样的，一个写入的一个呃测试

415
00:25:54,120 --> 00:25:55,830
这里面还写出了一个测试

416
00:25:55,890 --> 00:25:57,690
好，然后我们继续

417
00:26:01,110 --> 00:26:06,420
然后这个是这个是最后就是写开开了啥的

418
00:26:06,425 --> 00:26:09,360
参数之后，然后我们写了一段时间

419
00:26:09,365 --> 00:26:12,180
然后大家可以看到这么一个监控的一个状

420
00:26:12,420 --> 00:26:13,020
啊？

421
00:26:13,470 --> 00:26:18,540
从tak k监控呢，可以看到一个情况，就是说一开始的时候

422
00:26:18,780 --> 00:26:21,180
就是1555的时候

423
00:26:21,360 --> 00:26:25,200
这个时候呢，所有的写入的扣两次都在

424
00:26:25,380 --> 00:26:27,570
他跟那四四这个节点上面

425
00:26:27,930 --> 00:26:31,860
好，然后随着写入呢，然后大家也可以看到啊！

426
00:26:32,040 --> 00:26:34,980
啊她跟六五，然后还有他是唯一

427
00:26:35,190 --> 00:26:40,200
他们的写入了一个客户下去都是上涨还是然后他kv 4就逐渐降低了

428
00:26:40,380 --> 00:26:45,690
好，然后从这个趋势，大家就可以看到看到这个参数之后呢？

429
00:26:45,840 --> 00:26:47,880
随着它的写入

430
00:26:48,060 --> 00:26:53,370
随着数据量写入，当然就是我们因为有一位微整的一个概念

431
00:26:53,375 --> 00:26:55,800
所有需要有一定的数据量

432
00:26:55,980 --> 00:26:59,430
来支撑，然后瑞诊才可以当谈到

433
00:26:59,760 --> 00:27:03,270
呃，才可以打散到多个节点，多个kt几点上面？

434
00:27:03,870 --> 00:27:07,980
然后才可以达到一个相对的一个比赛的一个

435
00:27:08,250 --> 00:27:09,690
呃，状态对

436
00:27:10,890 --> 00:27:16,200
然后这个监控我们就可以看出来了，工作一段时间的协助，随着瑞呢因为

437
00:27:16,205 --> 00:27:20,610
数据的写入的流量，实际上是已经分到多少钱，加上面

438
00:27:20,910 --> 00:27:26,220
当然，我这个精选是因为只有三个节点，所以说大家看到了这么一个状态就

439
00:27:26,225 --> 00:27:28,650
可以理解的是，达到一个相对的平衡了

440
00:27:29,280 --> 00:27:31,470
然后这个我们

441
00:27:31,475 --> 00:27:36,780
再说一下，这个监控里面就是大家看到监控，可能是嗯，有一点儿以后

442
00:27:37,050 --> 00:27:39,690
比如说，可以不专业的代表什么原型？

443
00:27:39,810 --> 00:27:41,520
然后开始考虑材质是什么？

444
00:27:41,700 --> 00:27:46,560
我是看监控的时候，我是需要怎么来解读这个监控？

445
00:27:47,310 --> 00:27:52,620
啊，然后我们现在是只只说一下这一个件很像

446
00:27:52,625 --> 00:27:54,690
在这个监控项里面的

447
00:27:54,840 --> 00:28:00,150
就是说kv普锐@kv可逆点，然后还有就是下面的比如说靠不上

448
00:28:00,155 --> 00:28:01,830
开始了，我就陪你干去吧

449
00:28:01,920 --> 00:28:03,600
实际上都是指

450
00:28:03,605 --> 00:28:04,500
在

451
00:28:04,530 --> 00:28:07,800
她微微里面的短一些，API的一些操作

452
00:28:08,700 --> 00:28:14,010
然后kv主任在和kv可没想到实际上可以把它理解为是一个事物

453
00:28:14,700 --> 00:28:16,950
就说一个与写入和一个肯定的

454
00:28:17,010 --> 00:28:19,170
然后这个事物肯定在之后

455
00:28:19,410 --> 00:28:24,720
啊，就是在在kt里面之前的kvkvk之后，然后这个数据才算真正了一件

456
00:28:25,140 --> 00:28:26,130
写进去啦

457
00:28:26,370 --> 00:28:28,920
比如说你这个事物才能真正的成功了

458
00:28:29,100 --> 00:28:34,410
好，然后我们这边因为主要是一个写入一个操作，所以大家只能关心

459
00:28:34,415 --> 00:28:36,210
没准儿，然后隔壁的也可以啊！

460
00:28:39,570 --> 00:28:43,050
啊然后呢？当然，我们也可以从pg监控

461
00:28:43,140 --> 00:28:45,330
也可以看到这么一个状态

462
00:28:45,360 --> 00:28:48,960
然后嗯，还是依旧跟上面的

463
00:28:48,965 --> 00:28:54,270
监控是一样的，还是我们还是看这个热点，写入委整理的分布的这么一个？

464
00:28:54,275 --> 00:28:59,580
监控情况，然后大家可以看到我们上面的那个监控呢随着

465
00:28:59,585 --> 00:29:03,990
他的协助，实际上他的热点一直是在还是在一个节点上

466
00:29:05,130 --> 00:29:08,850
当然是在同一是同一时间内是在

467
00:29:09,120 --> 00:29:14,430
一一个开始在上面啊，那我们看这个监控就是我们做了扇子打伞之后

468
00:29:15,180 --> 00:29:20,490
然后随着他的协助，一开始只有这么一个黄色均线就开始数字四的一个

469
00:29:20,495 --> 00:29:24,690
12点好，然后随着写入到1602的时候

470
00:29:25,290 --> 00:29:30,600
我们这个渠道五就是他开始他他也有一个协议情况

471
00:29:30,605 --> 00:29:32,430
随着再T恤的写入

472
00:29:33,180 --> 00:29:38,490
继续随着写入，也就是说瑞典数量增多啊，然后拆开为14到1

473
00:29:38,640 --> 00:29:41,070
也有这么一个协会有一个请求啦！

474
00:29:41,880 --> 00:29:47,190
然后从而呢，就是大家可以看到后面取件他一直是一个比较均衡的一

475
00:29:47,195 --> 00:29:52,500
也就是说，也就是说在同一时间内，然后再多个她微微上面？

476
00:29:52,505 --> 00:29:53,160
面

477
00:29:53,670 --> 00:29:58,980
写入的一个请求的数量，或者是一个流量啊，实际上都是一个比较一个均衡

478
00:29:58,985 --> 00:29:59,670
转了

479
00:29:59,970 --> 00:30:05,280
然后这个状态了，这个状态就可以表示可能已经把这个热点的问题

480
00:30:05,285 --> 00:30:07,740
写写了两个问题给解决掉了

481
00:30:09,480 --> 00:30:11,160
你再看看下一个问题

482
00:30:11,790 --> 00:30:12,750
多热点

483
00:30:13,470 --> 00:30:14,070
不知道

484
00:30:14,220 --> 00:30:19,530
然后读热点就是为什么会产生毒了一点呢？当然这个问题呢，在一定

485
00:30:19,535 --> 00:30:24,840
程度上跟血也有关系，就是假如说你写的数据

486
00:30:24,845 --> 00:30:28,110
本身就是有弱点的，比如说啊！

487
00:30:28,140 --> 00:30:32,490
还是一个比较典型的一个例子，比如说就是写了一个日志归档的一个数

488
00:30:33,360 --> 00:30:37,320
好，那你写的这个数据，假如说本身就是一个

489
00:30:37,860 --> 00:30:42,720
有点点的，连续的一个数据好慢，你查的时候比如说我去查

490
00:30:43,110 --> 00:30:48,180
比如说2018年10月10号的一个数据，那这个区间的数据呢？因为它是连续的

491
00:30:48,480 --> 00:30:53,250
假如说又假如说这个数据没有那么大，就是说没有那么大的是指

492
00:30:53,310 --> 00:30:54,720
还没有分不到

493
00:30:55,290 --> 00:30:56,910
所有的他QQ上面

494
00:30:57,240 --> 00:31:02,550
啊，那这个时候假如说就是一个极端的例子，比如说这个书记那边一半，然后可能只能只

495
00:31:02,555 --> 00:31:04,770
在一个台上，这个就是一个瑞典

496
00:31:05,010 --> 00:31:09,690
啊，那这个时候呢，我们去发起一个查查询的一个请求

497
00:31:10,230 --> 00:31:15,540
但假如说这个请求又比较频繁，好，那这个请求，这个压力全都等到一个台湾厂厂长

498
00:31:15,930 --> 00:31:17,790
然后这个台式机呢就？

499
00:31:18,150 --> 00:31:23,460
产生了一个读的一个热点，也是说读热点的情况也是说

500
00:31:23,465 --> 00:31:26,130
会导致什么机器的这个？

501
00:31:26,610 --> 00:31:29,370
不管是CPU还是内存等等

502
00:31:29,970 --> 00:31:35,220
还有，当然也包括磁盘，然后四奶都会飙出，然后这个时候呢，就会

503
00:31:35,310 --> 00:31:40,620
额，这个时候就会发现好，因为我们是一个整个基础是一个

504
00:31:40,950 --> 00:31:43,260
整个的一个大腿，一个木桶

505
00:31:43,320 --> 00:31:44,820
那这一块儿

506
00:31:44,850 --> 00:31:49,140
然后他已经死了，然后变成一半了啊那这个

507
00:31:49,920 --> 00:31:55,230
虽然说你其他的剪剪上面还有很多空闲，可以加很多水，但是你这个咸咸一直在漏

508
00:31:55,380 --> 00:31:57,240
他这个性格上不去了

509
00:31:57,270 --> 00:31:58,740
所以就会导致

510
00:31:59,070 --> 00:32:01,230
整个集群的一个瓶颈

511
00:32:02,520 --> 00:32:05,160
然后我们下面呢，就是着重来看

512
00:32:05,190 --> 00:32:06,660
怎么判断？

513
00:32:06,810 --> 00:32:10,320
我们在用的这个集群是不是有多少点？

514
00:32:10,590 --> 00:32:13,440
然后假如说有确认已经

515
00:32:13,560 --> 00:32:15,210
确认是有毒的电脑

516
00:32:15,540 --> 00:32:18,540
然后我们这个读热点应该怎么解决？

517
00:32:21,390 --> 00:32:24,510
我们这边呢，也是通过一些

518
00:32:24,750 --> 00:32:26,940
呃，测试的数据来

519
00:32:27,060 --> 00:32:32,370
就是复现一下这个毒热点的一个场景啊，我们下面下面还是先看一下

520
00:32:32,375 --> 00:32:33,480
想赚的多点

521
00:32:33,960 --> 00:32:36,270
小白读热点，这个就比较简单

522
00:32:36,300 --> 00:32:38,880
这个表显示数据量很小

523
00:32:39,630 --> 00:32:42,030
就是说有个基本上左右

524
00:32:42,720 --> 00:32:45,960
然后呢，我们把这个小号数据导进去之后

525
00:32:46,410 --> 00:32:51,720
因为我们大家了解到的话就是可以知道能威震的大小，没认识

526
00:32:51,725 --> 00:32:53,040
是96张了

527
00:32:53,160 --> 00:32:58,470
那那假如说我们这个小组是比如说是啊100多兆或者200多兆那他

528
00:32:58,475 --> 00:32:59,970
它显示出之后

529
00:33:00,210 --> 00:33:05,520
它实际上只会产生两个位置，或者是三个瑞典那这个ri诊呢，可能就会

530
00:33:05,525 --> 00:33:07,500
分数在少数的几个

531
00:33:07,505 --> 00:33:08,580
还可以上面啊！

532
00:33:09,360 --> 00:33:13,890
然后大家我们大家可以看到下面的一个测试的一个

533
00:33:14,160 --> 00:33:19,440
呃搜索这个我们是用来搜狗最大的一个命令呃呃

534
00:33:19,740 --> 00:33:25,050
设置了一些并发，然后设置一些次数来对这个表，所以相对下次

535
00:33:25,055 --> 00:33:27,780
看了看星星然后就是相当于是一个全发表

536
00:33:28,170 --> 00:33:30,900
这个时候呢，这个小婊的

537
00:33:30,905 --> 00:33:32,760
数据分布，因为是不均的

538
00:33:32,765 --> 00:33:35,970
那这个时候我们在做这个操作的时候会发现

539
00:33:35,975 --> 00:33:39,030
好，我们的情况下

540
00:33:39,450 --> 00:33:43,140
然后做操作的时候做查询的时候可以发现好我们这个

541
00:33:43,170 --> 00:33:46,290
才可以，唯一的靠谱是三色是最高的

542
00:33:46,650 --> 00:33:51,090
可以看到，比其他的比其他两个才可以，要高了两倍多

543
00:33:51,270 --> 00:33:52,440
也就是

544
00:33:52,620 --> 00:33:55,350
也就是说，这个表的数据

545
00:33:56,370 --> 00:33:57,810
就是

546
00:33:57,990 --> 00:33:58,770
啊？

547
00:33:58,890 --> 00:34:01,380
多数都集中在了kv上面

548
00:34:01,500 --> 00:34:06,630
所以呢，他这边开开心心上的压力，看起来就比其他节点多了一倍

549
00:34:07,770 --> 00:34:13,080
然后我们再解决一下这个监控，这个监控的kv get和kv

550
00:34:13,085 --> 00:34:13,980
不会太小

551
00:34:13,985 --> 00:34:19,260
然后我们这里主要讲一下kk靠谱了他的靠谱儿的是啥意思呢？

552
00:34:20,130 --> 00:34:22,170
考试的30，就是指

553
00:34:22,410 --> 00:34:23,430
当你

554
00:34:23,580 --> 00:34:26,220
比如说业务上面啊，好就一个

555
00:34:26,250 --> 00:34:28,440
范围查询就是非检查的

556
00:34:28,470 --> 00:34:30,030
就是那种

557
00:34:30,120 --> 00:34:32,550
非那种等级查询的

558
00:34:32,580 --> 00:34:36,660
这种检查的一些借口，然后他都是走考本三才这个接口

559
00:34:37,560 --> 00:34:41,400
高尔台词相当于是在kv这一层都是做一个

560
00:34:41,610 --> 00:34:45,750
啊，相对的一个范围的一些查询，然后数据

561
00:34:45,780 --> 00:34:51,090
拿到数据之后，然后最最后再来反正给开金币这边对，然后KTV干

562
00:34:51,095 --> 00:34:55,290
看到实际上就是检查，大家就让大家这么一点就可以了

563
00:34:58,650 --> 00:35:03,960
他在霹雳上面怎么依旧可以看到五个点的？一个v的分布情况

564
00:35:04,920 --> 00:35:09,630
然后大家可以看到它跟微博上面的热点的历史是两个

565
00:35:09,720 --> 00:35:12,630
他们面试的时候，他跟a1上面分明是一个

566
00:35:13,350 --> 00:35:15,990
然后我们这个时候也可以判断出

567
00:35:16,110 --> 00:35:17,520
这个集群到

568
00:35:17,940 --> 00:35:21,660
恶毒热点是处于一个均衡的一个状态

569
00:35:22,260 --> 00:35:27,360
啊，然后有的同学可能比较细心，可以发现就是

570
00:35:27,510 --> 00:35:32,820
上面的呃，上面的监控呢？TK TV是比较高

571
00:35:32,825 --> 00:35:36,690
然后下面监控呢是他V5还高，为什么会？

572
00:35:36,750 --> 00:35:38,790
有这么一个现象呢？

573
00:35:38,820 --> 00:35:41,160
就是靠软件扫这个

574
00:35:41,310 --> 00:35:45,960
他表示的表示的是一个请求，所以是一个

575
00:35:46,170 --> 00:35:46,950
啊？

576
00:35:47,190 --> 00:35:49,020
怕死的一个数量

577
00:35:49,110 --> 00:35:50,070
然后

578
00:35:56,760 --> 00:36:02,070
然后这个霹雳这个监控呢？表示的是一个一的就是

579
00:36:02,075 --> 00:36:05,100
热点离得的一个分布的一个数量

580
00:36:05,250 --> 00:36:07,230
就是虽然说

581
00:36:07,260 --> 00:36:11,220
差别为50面粒粒粒粒的数量可能比较多

582
00:36:11,310 --> 00:36:12,420
但是呢？

583
00:36:13,470 --> 00:36:18,780
这些这这些历史对应的ri诊数据量可能比较小，所以说呢，他收到

584
00:36:18,785 --> 00:36:24,090
请求可能是啊，没有他认为上面的这个

585
00:36:24,420 --> 00:36:27,840
为更多对，所以会产生这么一个情况

586
00:36:29,850 --> 00:36:31,590
让我们继续往下

587
00:36:31,650 --> 00:36:34,470
就是说，除了通过监控

588
00:36:35,220 --> 00:36:40,530
我们也可以通过工具来看一下当时产生弱点的一个微整的

589
00:36:40,535 --> 00:36:41,340
ID

590
00:36:41,820 --> 00:36:47,130
当然了，这个我们只在恶毒热点列出来了，但是实际上写着点零

591
00:36:47,135 --> 00:36:52,440
也也可以通过这个被被砍头这个工具来判断就是哪个阶段？

592
00:36:52,445 --> 00:36:55,680
有12点啊，我这点的规章低于多少？

593
00:36:55,710 --> 00:36:58,320
也是可以通过这种方式来判断

594
00:36:58,800 --> 00:37:02,820
通过这种方式呢，我们已经拿到了热点了，日本ID

595
00:37:03,120 --> 00:37:06,090
然后呢，我们还可以通过一个AP

596
00:37:06,480 --> 00:37:11,790
但是这个AP就是啊，大家可以查一下就是说啊！

597
00:37:13,110 --> 00:37:18,420
我们官网的一些信息吧，然后可以看到一些相相关的一些内容

598
00:37:18,900 --> 00:37:19,530
对

599
00:37:20,400 --> 00:37:24,510
通过这个对应的A片呢？然后再加上这个已经

600
00:37:24,660 --> 00:37:27,990
已经获取到了位置，ID然后我们就可以

601
00:37:28,650 --> 00:37:33,960
通过这个信息来解析出这个数据对应

602
00:37:33,965 --> 00:37:35,190
是哪个表？

603
00:37:35,430 --> 00:37:40,290
然后通过，然后通过这个表达这个信息呢，然后我们就可以

604
00:37:40,470 --> 00:37:45,630
呃呃逆推出这个表对应哪些业务，然后他的数据的

605
00:37:45,780 --> 00:37:49,320
呃，存储是怎么样的？然后业务的逻辑也是存在的

606
00:37:49,410 --> 00:37:51,960
来判断一下，而这个表上面

607
00:37:52,020 --> 00:37:53,280
是不是？

608
00:37:54,750 --> 00:38:00,060
预期中就是存在这么一个热点，或者说是非语气呢？然后假设

609
00:38:00,065 --> 00:38:02,550
非预期的应应该怎么来优化？

610
00:38:04,440 --> 00:38:09,750
业务多热点，业务多了点，这个我们就快速的过一下业务多了点就是

611
00:38:09,755 --> 00:38:14,790
从根本上来说，跟小表的读数点实际上是一样的

612
00:38:14,820 --> 00:38:16,170
只是说

613
00:38:16,230 --> 00:38:18,240
业务有多少点呢，是因为？

614
00:38:18,480 --> 00:38:23,790
啊，不是因为他的数据量小，而是说他数据量已经足够大

615
00:38:23,795 --> 00:38:25,710
啊，他们已经足够大了，但

616
00:38:25,770 --> 00:38:27,120
但是呢？

617
00:38:28,770 --> 00:38:29,850
大事呢？

618
00:38:30,030 --> 00:38:35,040
他的呃，业务的特性，或者是业务逻辑的

619
00:38:35,370 --> 00:38:39,210
一些一些影响吧，然后导致数据

620
00:38:39,810 --> 00:38:40,830
在

621
00:38:41,190 --> 00:38:46,500
数据在这里面存储，然后以及查询就是一些

622
00:38:46,505 --> 00:38:47,700
查询业务

623
00:38:47,730 --> 00:38:48,720
在

624
00:38:48,725 --> 00:38:52,380
的业务逻辑上的一些特性，然后导致呢？

625
00:38:52,410 --> 00:38:57,720
然后请求的这些数据都是集中在少数的特别上面，所以呢？

626
00:38:57,725 --> 00:38:59,580
就会产生这么一个

627
00:39:00,270 --> 00:39:01,710
就点了一个情况

628
00:39:01,770 --> 00:39:07,080
啊，然后我们这边这边呢，依旧是用了MySQL原生的一个命令孩子

629
00:39:07,085 --> 00:39:08,280
一个压缩

630
00:39:09,180 --> 00:39:13,830
就是相当于是做一个压缩，然后大家也是说可以根据自己

631
00:39:13,920 --> 00:39:19,230
呃，机器的一个情况，然后根据自己集群的一个课程来的

632
00:39:19,235 --> 00:39:24,540
压力的一个情况，唉，自己设置一下这个并发数这个重庆的次数等等

633
00:39:26,550 --> 00:39:27,150
啊？

634
00:39:27,270 --> 00:39:28,380
然后我们

635
00:39:30,000 --> 00:39:34,230
知道了，这几个场景，他那么怎么来解决这个读者点吧？

636
00:39:35,400 --> 00:39:36,510
玩手机

637
00:39:37,500 --> 00:39:41,580
当出现毒热点的时候，然后可能有这么几个情况

638
00:39:41,610 --> 00:39:42,720
一个是

639
00:39:42,990 --> 00:39:46,920
假如说你正常情况下不应该出现多少点？

640
00:39:47,400 --> 00:39:52,620
但是呢，因为你的表走错了，所以导致少了更多的数据

641
00:39:53,130 --> 00:39:56,250
但因为我们是数据是按

642
00:39:56,850 --> 00:39:59,160
区间按范围，按顺序来

643
00:39:59,190 --> 00:40:04,110
真的就是就是就是这个微信的这么一个概念

644
00:40:04,350 --> 00:40:09,390
那这个时候呢，假如说走错了，所以然后导致

645
00:40:09,480 --> 00:40:14,790
扫扫了大范围的一个数据，那这个时候呢就可导致了这么一个热点的一个

646
00:40:14,795 --> 00:40:15,420
没事

647
00:40:16,260 --> 00:40:21,570
然后这个时候呢，也是说可以通过霹雳感受这些工具来确定

648
00:40:21,575 --> 00:40:26,880
热点的vid是多少？然后从而解析出对应的表是怎么样的？

649
00:40:27,420 --> 00:40:32,520
然后进而解析出我们对应的业务就是怎么样的啊？这些业务

650
00:40:32,880 --> 00:40:35,940
啊，这些业务思考是不是真的做错了？所以

651
00:40:36,030 --> 00:40:38,820
假如说真的走错词语啊！

652
00:40:39,150 --> 00:40:42,030
我们针对这个舌头，然后针对比较结构

653
00:40:42,035 --> 00:40:43,410
根据表结构

654
00:40:43,415 --> 00:40:45,600
来了这个时候做一些优化

655
00:40:46,440 --> 00:40:51,750
或或者说是呃，重新收集一下啊信息，或者说是加息

656
00:40:51,755 --> 00:40:52,530
真的

657
00:40:53,460 --> 00:40:56,160
来解决这个走错索隐的问题

658
00:40:56,580 --> 00:41:01,890
还有第二个，第二个就是我们说的小婊的多一点就小点儿，11点儿

659
00:41:02,520 --> 00:41:07,830
分布就是虽然没有那么大了，然后分数据的分布只在少数几个QQ上面

660
00:41:08,280 --> 00:41:11,700
啊，那这个时候呢，再加上就是想想，可能有一个

661
00:41:12,030 --> 00:41:16,020
比较高频率的一些增删改查等系列操作

662
00:41:16,200 --> 00:41:17,040
然后

663
00:41:17,070 --> 00:41:19,080
就会导致这么一个

664
00:41:19,140 --> 00:41:22,710
小小个弱点的一个情况，那这个时候怎么解决呢？

665
00:41:23,700 --> 00:41:25,050
你们带PT

666
00:41:25,200 --> 00:41:30,510
就是被地砍头这个工具，他支持一个功能，就是说可以人为的

667
00:41:30,780 --> 00:41:34,680
来对来把这个表的微信来做一个切分

668
00:41:34,685 --> 00:41:37,020
就是你原来比如有三个位置啊？

669
00:41:37,230 --> 00:41:38,940
然后我给他签一下

670
00:41:38,945 --> 00:41:43,020
啊，变成六个了然后你甚至还可以再写好变成12个了

671
00:41:43,200 --> 00:41:45,000
然后这个危险多了之后

672
00:41:45,630 --> 00:41:47,190
这个说这个

673
00:41:47,430 --> 00:41:49,050
数据的分布

674
00:41:49,055 --> 00:41:50,550
因为他是一个

675
00:41:50,555 --> 00:41:52,620
呃，自动发的是一个过程

676
00:41:52,920 --> 00:41:56,190
然后随着数据的84，随着数据有调动

677
00:41:56,700 --> 00:42:01,950
然后这个表的数据相当于是也是达到了一个相对的一个平衡的一个状态

678
00:42:02,190 --> 00:42:07,500
然后这个时候呢，就就算是业务不变啊，那这个时候因为他

679
00:42:07,505 --> 00:42:08,220
对吧？

680
00:42:09,060 --> 00:42:12,180
更加离散了，所以说也是达到了一个

681
00:42:12,930 --> 00:42:15,060
解决读者点的一个

682
00:42:15,360 --> 00:42:16,320
啊？

683
00:42:17,850 --> 00:42:21,030
解决多少点的一个效果吧

684
00:42:22,260 --> 00:42:24,900
还有一个问题就是说

685
00:42:25,530 --> 00:42:27,330
思考就是

686
00:42:27,630 --> 00:42:30,150
执行计划有问题，没有做错，所以

687
00:42:31,050 --> 00:42:36,360
但是呢，但是呢，因为他的业务模型就是或者说是一

688
00:42:36,365 --> 00:42:39,270
由于它的一个业务的逻辑的一个

689
00:42:39,630 --> 00:42:44,940
的影响导致呢他频繁地去扫一些范围的

690
00:42:44,945 --> 00:42:50,250
一一些数据啊，这个时候产品的一个热点就是还是说啊

691
00:42:51,330 --> 00:42:54,000
比如说吧，比如说是订单数

692
00:42:54,090 --> 00:42:58,260
啊，那订单付的话一般呢，就是说查某一天的一个

693
00:42:58,680 --> 00:43:00,240
啊，订单的一个信息

694
00:43:00,270 --> 00:43:02,100
那这个时候呢，可能

695
00:43:02,790 --> 00:43:04,380
今天是啥？

696
00:43:04,385 --> 00:43:09,690
这个数据这个区间数据明天查查那个区间的数据那这个少年力每天都会有

697
00:43:09,695 --> 00:43:10,830
有这么一个

698
00:43:11,280 --> 00:43:15,720
读热点的一个情况，而且每天对应数据都是不一样的

699
00:43:16,350 --> 00:43:18,420
那这个时候我们怎么来解决呢？

700
00:43:18,570 --> 00:43:21,450
因为数据是在

701
00:43:21,840 --> 00:43:26,910
泰迪b里面，然后在他可以嗯，也就是说在他这里面是已经去了

702
00:43:27,090 --> 00:43:30,450
那既然已经存进去了然后业务逻辑就是这样的

703
00:43:30,930 --> 00:43:36,240
你们是只能是从根本上来解决这个问题，也就是说在数据写

704
00:43:36,245 --> 00:43:37,200
这个时候

705
00:43:37,470 --> 00:43:39,000
直接把这个数据打伞

706
00:43:39,720 --> 00:43:41,970
尽量不要让这个数据

707
00:43:42,150 --> 00:43:47,460
然后落到同一个，或者说是轮到少数的几个

708
00:43:47,465 --> 00:43:52,770
因为上面啊，这个时候你们应该去做一些查询的一些成本相当于是也是

709
00:43:52,775 --> 00:43:55,170
达到了一个打伞的一个效果

710
00:43:56,130 --> 00:43:57,690
对当然了

711
00:43:57,960 --> 00:43:59,940
就是说嗯

712
00:44:00,120 --> 00:44:05,430
虽然说业务上面可能有一些表就是说啊，范围查询

713
00:44:05,435 --> 00:44:08,670
很多，但是呢，他不一定

714
00:44:08,850 --> 00:44:10,470
就是不一定会有

715
00:44:10,530 --> 00:44:15,750
这个热点的情况，因为毕竟在我们真正业务上面可能会有很多个表

716
00:44:15,900 --> 00:44:18,090
可能有的业务啊！

717
00:44:18,690 --> 00:44:22,590
更加大一点，可能有几万个表等等这种猪之类的

718
00:44:22,650 --> 00:44:24,600
那你随着业务的

719
00:44:25,500 --> 00:44:30,750
增多，实际上每一个表，比如说每个表都有一个稍微比较

720
00:44:31,320 --> 00:44:36,630
想到一个热点的情况，那你这么多人加起来实际上也是相对的，达到了一个

721
00:44:36,635 --> 00:44:38,580
挺好，只要说是

722
00:44:38,585 --> 00:44:43,890
没有上没有某一个表，或者说是少数几个表现特别明显的一个

723
00:44:43,895 --> 00:44:44,700
一个

724
00:44:44,910 --> 00:44:49,830
啊，又是范围查询，然后就是平衡的特别高啊，导致了一个严重的问题

725
00:44:49,835 --> 00:44:51,690
这样没有这种问题就可以了

726
00:44:51,840 --> 00:44:57,150
不是说碰到这种场景，都一定要把这个表来做一些变更

727
00:44:57,330 --> 00:44:58,740
咱们都数据大全

728
00:45:01,440 --> 00:45:05,280
好让我们然后我们继续往下看一下事务冲突

729
00:45:05,550 --> 00:45:10,860
然后事务冲突呢？这个就是比较简单，因为大家平常的话啊！

730
00:45:10,865 --> 00:45:13,950
也是遇到的比较多啊，对这一块了解释

731
00:45:14,070 --> 00:45:16,680
呃，都比较多，然后就快速过一下

732
00:45:17,580 --> 00:45:20,490
然后这个问题呢，就是说

733
00:45:20,495 --> 00:45:24,960
大家需要关注一下啊，我们什么场景会发生的事物冲突？

734
00:45:25,110 --> 00:45:26,940
我这个呢，大家都需要

735
00:45:27,030 --> 00:45:28,680
看看一下啊！

736
00:45:28,710 --> 00:45:34,020
推币和麦收购的一些区别，因为我们合买收购的

737
00:45:35,430 --> 00:45:38,790
是就是在做这方面是不一样的

738
00:45:39,510 --> 00:45:44,820
买烧烤，上面是一个悲观锁，我们是乐观锁，乐观锁，乐观锁的是在提交

739
00:45:44,825 --> 00:45:47,280
到的时候才会去检查这个社会制度

740
00:45:47,670 --> 00:45:52,980
然后宾馆所呢？是你比如说好艺术冲突，你这样的去赶着

741
00:45:52,985 --> 00:45:57,480
然后接触只想之后第25才去执行啊，所以呢？

742
00:45:58,110 --> 00:46:02,970
假如说在泰迪b这种加入上面有比较严重的收入冲突

743
00:46:03,060 --> 00:46:06,570
那也就是说，你有很多的事物都是在

744
00:46:06,575 --> 00:46:11,700
提交的时候就是说已经主任谈完了，在啃爪子的时候好，然后发现了

745
00:46:11,760 --> 00:46:12,930
好这个冲突

746
00:46:13,020 --> 00:46:13,770
然后

747
00:46:13,775 --> 00:46:19,080
回去然后这个这个大质量的操作实际上还是在还是？

748
00:46:19,085 --> 00:46:23,640
是很消耗这样的，然后就算是资源能够支撑的住

749
00:46:24,000 --> 00:46:29,310
但是由于这个大批量的输冲突导致的一些同事

750
00:46:29,315 --> 00:46:34,620
是这种，然后也会导致业务上面会出现很多的一些那些水

751
00:46:34,740 --> 00:46:39,300
总之来说，就是说假如说出现比较严重的事务冲突

752
00:46:39,360 --> 00:46:41,700
对用户这边来说，感受是

753
00:46:41,760 --> 00:46:42,840
什么好啊？

754
00:46:43,290 --> 00:46:46,230
好，那我们怎么来定位这个社会冲突？

755
00:46:46,235 --> 00:46:50,430
以及怎么来解决这个输出？当然解决的话，就大家都知道

756
00:46:50,640 --> 00:46:53,940
就是改一下业务，或者是啊！

757
00:46:54,210 --> 00:46:57,780
避免电话这些冲突的这些业务就可以了

758
00:46:59,010 --> 00:47:03,030
啊，然后说冲突啊，这个是

759
00:47:04,290 --> 00:47:05,070
啊？

760
00:47:05,820 --> 00:47:07,650
这个是我们在

761
00:47:08,190 --> 00:47:13,440
她的病内部实现上面的，实际上在内部有也有一些就是

762
00:47:13,980 --> 00:47:18,420
针对于一些事儿，一些事物冲突比较好

763
00:47:18,660 --> 00:47:23,400
呃，没有那么强的一些场景做了一些内部的一些城市，就是说用户

764
00:47:24,060 --> 00:47:29,370
就是说对用户不可见，但是说你这个事物虽然说是有有那么

765
00:47:29,430 --> 00:47:34,740
稍微一点的一些冲突，但是经过内部的一个城市，在用户不可见的一个情况下

766
00:47:35,670 --> 00:47:40,950
然后他也能在执行的重视了n次之后才成功

767
00:47:40,955 --> 00:47:46,260
比如说对用户在某一些程度上来说也是比较友好的一个实现啊！

768
00:47:46,590 --> 00:47:51,900
然后第二个就是说用户可见了一个返回的一个错误信息，这个呢就是说

769
00:47:51,905 --> 00:47:54,120
在系统内部

770
00:47:54,210 --> 00:47:59,520
从事次数已经超过了一个预支了，超过了某一个预支了然后这个时候呢，他也不能

771
00:47:59,525 --> 00:48:00,750
无限的去城市

772
00:48:00,840 --> 00:48:03,210
所以呢，这个时候就会给用户

773
00:48:03,215 --> 00:48:07,590
给客户端这边返回一个错误信息啊，就是说我这个是五

774
00:48:07,800 --> 00:48:13,110
因为有有其他事物在做做的操作，然后正好这边有一个

775
00:48:13,115 --> 00:48:18,000
这个这个重试完了之后没办法成功不了，只能是找出一个错误

776
00:48:18,120 --> 00:48:23,430
然后你这边啊，跟着这个错误信息，然后人工在做这边在这里

777
00:48:23,435 --> 00:48:28,740
要做一些逻辑的判断，等等等好好再去做一些尝试啊，或者说是做一些优化

778
00:48:28,745 --> 00:48:31,680
当当当当是啊，这些操作对

779
00:48:33,270 --> 00:48:35,460
然后呢，怎么定位也是五寸图？

780
00:48:35,580 --> 00:48:38,100
然后我们这边呢，主要就是看

781
00:48:38,105 --> 00:48:41,610
这个事物冲突就是这个集群事务冲突是不是严重？

782
00:48:42,750 --> 00:48:45,000
啊，我们这边也是有两个监控

783
00:48:45,270 --> 00:48:49,410
啊，这个都是KTV呃，这个监控界面上面的

784
00:48:49,590 --> 00:48:51,360
啊，一个是

785
00:48:51,510 --> 00:48:56,820
K KTV与mo US然后这个呢就是指有所的时候，然后

786
00:48:57,690 --> 00:49:03,000
啊，就是假如说你急成那个有锁，然后再这样的事物去做一些操作的事

787
00:49:03,005 --> 00:49:08,310
他可以去检查这个上一个收缩索，然后是不是过期了啊是不是？

788
00:49:08,315 --> 00:49:09,270
能祛掉

789
00:49:09,390 --> 00:49:10,230
然后

790
00:49:10,590 --> 00:49:11,700
到了

791
00:49:11,820 --> 00:49:17,130
出现就是说有这些操作的时候，然后这个监控就是就是指比较多

792
00:49:17,135 --> 00:49:20,760
然后然后这个监控值比较高的时候就说明

793
00:49:20,765 --> 00:49:24,450
就是从侧面就说明这个集团内部

794
00:49:24,480 --> 00:49:27,600
是有比较多的一个冲突

795
00:49:27,750 --> 00:49:32,640
因为毕竟是有锁，然后他们可以去检查，然后才会去尝试，就这个锁

796
00:49:32,820 --> 00:49:35,580
然后有这个操作的时候，这个健康才会高

797
00:49:35,585 --> 00:49:36,570
所以说

798
00:49:36,575 --> 00:49:41,880
可以反馈一下，就是说只要这个监控高了一一定是这个集群

799
00:49:41,885 --> 00:49:45,360
里面还有比较多的一个冲突

800
00:49:46,380 --> 00:49:48,270
然后下面这个监控

801
00:49:48,360 --> 00:49:52,620
啊啊，告诉我给你看，然后这个呢就是指我们在

802
00:49:53,220 --> 00:49:58,530
内部重视的时候，内部城市的时候就是这个拔高否不一定要是指所重

803
00:50:00,150 --> 00:50:01,680
不一定是指事务冲突

804
00:50:01,685 --> 00:50:06,990
还有可能，比如说有一些人就是密丝啊，比如说有一些那个能合理点儿这种信息

805
00:50:07,110 --> 00:50:12,420
然后也是说内部会产生一个版号好，也就是说可以理解为是一个内部的城市

806
00:50:12,990 --> 00:50:17,040
就是说她就不想去给他们发一个请求，哈哈，我要查查数据

807
00:50:17,580 --> 00:50:22,890
但是太开心了，这边好，他正在切地的好人，我这个阶段已经不是

808
00:50:22,895 --> 00:50:28,200
这里的好像，然后这个时候呢，他开车就会给那个，她就说我这个年龄已经不是比赛

809
00:50:28,205 --> 00:50:29,730
然后你去

810
00:50:29,735 --> 00:50:35,040
房子也是房子的那个，比如说房子去嗯，比如说你去房子里，特别v200

811
00:50:35,045 --> 00:50:38,340
啊，他现在是谁的啊？然后这个时候就会想看就完了

812
00:50:39,390 --> 00:50:41,760
这个是正常的，然后

813
00:50:41,910 --> 00:50:46,980
然后我们把它列到这儿呢，主要就是说这个监控，它里面有一项是

814
00:50:47,250 --> 00:50:50,640
Ts，升落个饭饭，然后这个监控项呢？

815
00:50:50,910 --> 00:50:52,410
它代表着

816
00:50:52,740 --> 00:50:53,670
受冲突

817
00:50:53,970 --> 00:50:57,930
就是指，也是指泰迪配合他这个之间的，然后也是

818
00:50:58,470 --> 00:51:03,780
当这个职业高的时候就能反映出这个集群内，然后锁冲突是比较严重的

819
00:51:03,930 --> 00:51:05,880
也就是说，受众都是比较严重

820
00:51:07,500 --> 00:51:12,240
然后大家一般就可以通过这两个监控去做一些判断

821
00:51:12,245 --> 00:51:13,590
就是比较

822
00:51:13,980 --> 00:51:14,790
啊？

823
00:51:14,850 --> 00:51:16,770
比较明显的一些判断，对吧？

824
00:51:17,070 --> 00:51:22,380
然后除了监控之外呢，从这里面也可以分析到一些

825
00:51:22,385 --> 00:51:23,550
电话得鲜那种

826
00:51:23,555 --> 00:51:25,920
啊，他的病里面啊！

827
00:51:26,010 --> 00:51:30,240
会有一些乱砍康利的，就是说小冲突了，因为我们

828
00:51:30,750 --> 00:51:36,060
对于他开始来说，然后他特别底下实际上是让BB，然后它里面的时间上

829
00:51:36,360 --> 00:51:39,600
都是一些库存的一些呃一些普通的一些操作

830
00:51:39,780 --> 00:51:42,210
对然后所以说

831
00:51:42,300 --> 00:51:45,960
有事物去做些操作的时候都会去

832
00:51:46,020 --> 00:51:50,220
呃，做一些写入，然后当参加所的时候，就会把一个人健康非常

833
00:51:52,080 --> 00:51:56,280
然后呢，还有一个日志的一个信息就是她的位置这里面

834
00:51:56,580 --> 00:51:59,160
在这个日子里面呢，你能看到

835
00:51:59,400 --> 00:52:02,640
这个事物虽然说冲突了然后

836
00:52:02,970 --> 00:52:08,100
冲突之后呢？他就是内部从事了多少次，有一个水菜看到

837
00:52:08,370 --> 00:52:13,680
然后大家就可以看到这个职业有些是零了，依赖或者说是酒啦，我们就说能看

838
00:52:13,685 --> 00:52:15,720
这个借口种是多少次？

839
00:52:15,930 --> 00:52:20,880
然后大家通过这个关键字呢，也可以看到是哪个档口？

840
00:52:21,450 --> 00:52:22,590
他们的同事

841
00:52:22,710 --> 00:52:28,020
因为这个社会里面呢，它会包含一些相关的信息，大家就可以知道一点点，然后

842
00:52:28,025 --> 00:52:29,370
是

843
00:52:30,000 --> 00:52:33,960
具体对应什么业务，然后做一些具体的一些判断

844
00:52:34,230 --> 00:52:38,010
然后根据这个东西呢，可以针对业务做一些优化

845
00:52:38,460 --> 00:52:42,180
还有就是skt，当时这个泰克威了，一般情况下

846
00:52:42,630 --> 00:52:44,730
这个日子不用特别关注

847
00:52:45,090 --> 00:52:49,800
啊，就是说假如说碰到的话，知道这个信息的人知道这个信息就可以了

848
00:52:50,070 --> 00:52:52,470
比如说他在这里面会有一些哎呦

849
00:52:52,560 --> 00:52:55,710
当然这个哎呀，我就是看起来吓人，但是实际上

850
00:52:56,190 --> 00:52:59,730
可以往后看看，后面也可以看到是那个

851
00:53:00,210 --> 00:53:05,070
克拉克v lock，实际上就是代表发生了一个事冲突

852
00:53:05,460 --> 00:53:08,460
也就是说，在kt这边发生了一个锁的冲突

853
00:53:08,880 --> 00:53:10,650
实际上这个

854
00:53:10,980 --> 00:53:16,290
要不然就是他内部的一些自动城市，然后从事检测之后哈成功

855
00:53:16,980 --> 00:53:22,290
呃，也就可以忽略了，还有就是可能是重申一下，之后还为用户这边，或者说是

856
00:53:22,295 --> 00:53:25,410
还给扣端这边好，我这边有一个

857
00:53:25,530 --> 00:53:27,060
啊，有一个比较

858
00:53:27,210 --> 00:53:28,140
啊？

859
00:53:28,980 --> 00:53:30,750
就是比较多的一个冲突

860
00:53:31,290 --> 00:53:36,600
小肚子时候冲突，然后用然后用户测呢再登录这个信息来做一些优化就可以了

861
00:53:39,930 --> 00:53:45,240
啊，然后卖开学卖他学我们这边放到最后讲是因为？

862
00:53:45,245 --> 00:53:48,690
下面的几个场景就写热点，多热点

863
00:53:49,080 --> 00:53:52,560
和受冲突，实际上都可以导致吗产品？

864
00:53:53,040 --> 00:53:55,710
所以我们把安排学员放到这三个后面来讲

865
00:53:56,190 --> 00:54:01,470
然后慢查询的这个出现的可能性还是有比较多

866
00:54:01,500 --> 00:54:06,810
然后当然也不仅仅是他这段时间要买车子上面也有可能有这些

867
00:54:06,990 --> 00:54:11,100
问题啊，我们这边就练了一下这个下

868
00:54:11,105 --> 00:54:12,210
就是

869
00:54:12,750 --> 00:54:15,270
出现频率比较高的一个

870
00:54:15,720 --> 00:54:17,100
原因对

871
00:54:17,760 --> 00:54:19,530
然后网络延迟高

872
00:54:19,650 --> 00:54:24,960
啊，这个嗯，实际上是属于库里一个共性，假如说啊，可让他到所有人

873
00:54:24,965 --> 00:54:28,200
这边好网络已经吃高了，比如那个500毫米

874
00:54:28,320 --> 00:54:31,200
那这个时候数据库这边性能再好

875
00:54:31,320 --> 00:54:35,700
因为你这个中间从高端到所有这边的一个网络

876
00:54:35,850 --> 00:54:37,230
延迟高

877
00:54:37,320 --> 00:54:42,630
那这个一直到你拿到结果再返回来，然后对用户的证明来说

878
00:54:42,635 --> 00:54:47,940
好他敢他感受到了这个城市的那个人，但实际上并不属于不等于

879
00:54:47,945 --> 00:54:48,660
问题

880
00:54:49,740 --> 00:54:53,130
好然后硬件性能问题，这个也是

881
00:54:53,190 --> 00:54:54,090
啊？

882
00:54:56,010 --> 00:55:01,320
就是不用太过多的说了，就是当然硬件出问题，然后一般都伴随着

883
00:55:01,325 --> 00:55:05,370
性能好像强性能下降了，这个数据库啊！

884
00:55:05,375 --> 00:55:09,000
一些查询吧家接入了，等等也有相应的就变慢了

885
00:55:09,900 --> 00:55:12,510
啊，还有进行负载高

886
00:55:12,570 --> 00:55:17,880
就是比如说啊，你激情压力特别大的，比如说可能有一些a EP的一些操作

887
00:55:17,885 --> 00:55:23,190
然后导致占用了很多的资源，然后单位数据库压力大的时候

888
00:55:23,790 --> 00:55:28,260
自然想到已经办了，也就自然了，也就产生了一个念大学的啊

889
00:55:28,860 --> 00:55:31,230
然后还有就是说冲突

890
00:55:31,290 --> 00:55:36,600
啊，这个就不能说了，还有就是个借口走错，所以啊，也就是说，执行计划是

891
00:55:36,720 --> 00:55:38,400
错了，你比如说啊！

892
00:55:38,430 --> 00:55:43,740
所有的可能是去找a所言，但是呢，然后可能是因为一些

893
00:55:43,745 --> 00:55:48,930
成绩信息的原因，或者说是因为一些嗯，其他的原因导致走了闭所以

894
00:55:48,990 --> 00:55:54,300
那这个时候可能好房的数据更多了，我说是计算更多了，导致产生一个大学

895
00:55:55,830 --> 00:55:57,300
然后我们

896
00:55:57,390 --> 00:56:00,480
知道，让她选产品原因我们下面就要看

897
00:56:00,750 --> 00:56:04,500
我们怎么定位这个慢慢选？到底是怎么产生的？

898
00:56:04,680 --> 00:56:05,610
他的

899
00:56:05,615 --> 00:56:07,410
具体原因是怎么样的？

900
00:56:08,430 --> 00:56:10,710
假如说是真的是

901
00:56:11,100 --> 00:56:12,720
啊，走错了所以

902
00:56:13,710 --> 00:56:17,250
你们从这里面怎么判断他是否则厕所所？

903
00:56:17,255 --> 00:56:19,620
他走错了就走错了哪一个？

904
00:56:20,880 --> 00:56:22,380
啊然后呢？

905
00:56:22,710 --> 00:56:28,020
走错了之后呢，我们又要怎么我们又该怎么去？又怕让他走到正确的

906
00:56:28,025 --> 00:56:29,250
可以上面

907
00:56:30,480 --> 00:56:31,680
我们继续

908
00:56:33,360 --> 00:56:38,670
这边是有一个例子，然后也是我们这边模拟的一份数据，然后大家可以

909
00:56:38,675 --> 00:56:40,950
看到好我们这边有一个搜狗

910
00:56:40,955 --> 00:56:42,900
他的嗯

911
00:56:43,110 --> 00:56:48,030
这个算法是来模拟迈大学的，然后下面是他的表结构，然后大家可以看到

912
00:56:48,150 --> 00:56:51,090
假结构里面只有一个主键就是

913
00:56:51,095 --> 00:56:55,200
考了一，这个算还有一个英大还是碳这个字段

914
00:56:56,430 --> 00:57:01,740
啊，然后大家可以看到啊，我们这个社会呢，里面是八号

915
00:57:01,745 --> 00:57:03,030
换了一个看不知道

916
00:57:03,330 --> 00:57:07,590
然后李莹来说呢，他应该是走到太姥这个，所以

917
00:57:07,680 --> 00:57:09,030
然后再根据

918
00:57:09,090 --> 00:57:12,120
这个索引过滤出来的那个数据，再去做一个

919
00:57:12,270 --> 00:57:14,970
呃，看到我们三这个阶段的一个判断

920
00:57:15,690 --> 00:57:17,190
这个强调的一个顾虑

921
00:57:19,890 --> 00:57:20,940
然后

922
00:57:21,630 --> 00:57:26,550
啊，我们上面只是一个例子啊，然后大家碰到具体的情况，然后

923
00:57:26,670 --> 00:57:31,980
可以去根据这个收口表结构，还有执行计划，然后去具体的分析

924
00:57:32,730 --> 00:57:35,280
然后我们上面的思考执行之后呢？

925
00:57:36,210 --> 00:57:41,520
通过监控可以看到好这个这个是泰迪b的监控，然后上面有监控

926
00:57:41,525 --> 00:57:43,860
还是比较全的，然后有各种

927
00:57:43,920 --> 00:57:47,130
延迟的信息，还有各种扩展的信息都可以看

928
00:57:47,250 --> 00:57:50,070
啊，我们这边呢，从第一个监控可以看到

929
00:57:50,550 --> 00:57:54,690
对于整个集训来说啊，我出现了一个慢查询

930
00:57:54,870 --> 00:57:55,650
然后

931
00:57:55,980 --> 00:57:59,160
就是查询录取线高了，也就是查询时间高了

932
00:57:59,165 --> 00:58:01,830
所以说，可以判断出出现了卖茶水

933
00:58:02,190 --> 00:58:05,400
啊，然后我们第一个监控呢，因为它只是一个概念

934
00:58:06,240 --> 00:58:08,760
就说我们是分布式的，可能有多个角度

935
00:58:09,630 --> 00:58:13,650
你能知道这个集群是出现了个大学，但是你不知道是哪个才是？

936
00:58:13,860 --> 00:58:15,750
啊，所以我们还有其他的监控

937
00:58:15,870 --> 00:58:17,640
就是更细化的

938
00:58:18,030 --> 00:58:21,900
然后我们再看下面的监控下面监控呢，我们就可以看到

939
00:58:21,930 --> 00:58:22,950
右边

940
00:58:22,955 --> 00:58:26,460
看到是哪个IP？哪个端口？

941
00:58:26,520 --> 00:58:31,230
然后通过这个信息呢，就可以判断出是哪个台ABB的？

942
00:58:31,440 --> 00:58:34,260
是哪个台的命？这边出现了观察者

943
00:58:35,310 --> 00:58:36,060
继续

944
00:58:37,290 --> 00:58:38,460
然后呢？

945
00:58:38,465 --> 00:58:42,540
在这个台湾币节点上面，我再去看他的，慢慢谈谈日志

946
00:58:42,990 --> 00:58:46,860
慢查询日志里面呢，我可以看到相关的一些信息

947
00:58:46,950 --> 00:58:49,080
比如说啊，柚子ID

948
00:58:49,110 --> 00:58:50,700
从哪个接点过来的？

949
00:58:51,150 --> 00:58:53,280
比如说那个跨越太大

950
00:58:53,340 --> 00:58:55,260
这个烧烤执行多长时间？

951
00:58:55,590 --> 00:59:00,900
然后他说他们下面也得好啊，这个内容是比较多，你们不好像是好像是晒得太阳包含

952
00:59:00,905 --> 00:59:02,010
真是太难了

953
00:59:02,520 --> 00:59:07,830
然后我说现在太阳能，然后大家可以看到的好，这个普通太太就是执行时间的人比差

954
00:59:07,835 --> 00:59:08,610
开始时

955
00:59:09,060 --> 00:59:10,440
还要吵对吧！

956
00:59:11,010 --> 00:59:16,320
然后这个是一些新用户刚接触的时候会有这个疑惑

957
00:59:16,710 --> 00:59:18,030
然后这里

958
00:59:18,060 --> 00:59:20,100
呃，这个我们来解释一下

959
00:59:20,220 --> 00:59:22,140
总算看了是指

960
00:59:22,680 --> 00:59:24,000
啊？

961
00:59:24,030 --> 00:59:29,340
我们先说一下那个查询的一个过程，查询的话是用户这边啊思考

962
00:59:29,345 --> 00:59:30,780
发给

963
00:59:30,870 --> 00:59:34,200
神经病啊，他就一直背对窗口做一个解析

964
00:59:34,230 --> 00:59:39,540
然后再根据呃解析出来结果，然后以及数据的

965
00:59:39,545 --> 00:59:41,700
分布的一个情况啊，这个

966
00:59:42,000 --> 00:59:47,310
最硬的请求发给不同的了，隔壁上面，也就是说你在做一个思考查询的

967
00:59:47,315 --> 00:59:47,970
啥好？

968
00:59:47,975 --> 00:59:51,600
实际上是在同时去多个台kv上面

969
00:59:51,660 --> 00:59:53,130
然后去做一个查询

970
00:59:53,220 --> 00:59:58,230
然后他也她微微上面的还可以，戏份就是每个台微微上面的室友

971
00:59:58,235 --> 00:59:59,430
很多个睿智

972
01:00:00,090 --> 01:00:02,010
而且这个查询呢，可能是

973
01:00:02,040 --> 01:00:06,090
每个开开车上面都要去多个N多个微信上面去

974
01:00:06,180 --> 01:00:07,170
拿这么久

975
01:00:07,290 --> 01:00:11,610
对应的一个数据，所以说呢，这个普通赛特的实际上

976
01:00:11,670 --> 01:00:16,020
是把所有他可以上面，然后每一个睿智的一个

977
01:00:16,890 --> 01:00:21,000
做查询的这么一个时间，然后做了一个总结

978
01:00:22,110 --> 01:00:25,200
所以说看起来会比快乐太难，要高

979
01:00:25,350 --> 01:00:27,810
然后v的态度也是因为他，我是指

980
01:00:27,815 --> 01:00:31,470
对多个台kv上面的多个微诊去做

981
01:00:31,560 --> 01:00:34,950
一些查询或者说是做一些其他操作的话

982
01:00:35,130 --> 01:00:39,000
然后在每个上面等待的时间的一个统合

983
01:00:39,540 --> 01:00:44,850
对然后这个就是可以从一定角度，从一定程度上来反应出

984
01:00:44,855 --> 01:00:47,490
这个时候到底是卖在哪里啊？

985
01:00:48,420 --> 01:00:52,500
然后还有后面的一些也都可以啦，还有普通话就可以拿这个就是指

986
01:00:52,590 --> 01:00:56,580
这个舌头在kv这边，嫂子kv的数据

987
01:00:57,030 --> 01:00:59,730
嫂子KB的属于这个k就是指批发的

988
01:00:59,850 --> 01:01:01,650
走了天涯六的数据有多少？

989
01:01:02,430 --> 01:01:07,740
好，然后下面还有弟弟就是对应是哪个数据库？还有也得硬

990
01:01:07,745 --> 01:01:10,800
然后这个呢，是指这个

991
01:01:11,460 --> 01:01:16,050
对应的办法学习系统内部的锁口还是说是用户

992
01:01:16,380 --> 01:01:21,360
这边执行的一个蛇口，如果是系统内部的时空呢？实际上是可以忽略的

993
01:01:22,200 --> 01:01:23,460
如果是

994
01:01:23,490 --> 01:01:27,780
啊，假如说这个值是放松，也就是说这个借口实际上是

995
01:01:27,900 --> 01:01:31,500
呃，用户这边是业务上相关的一个借口

996
01:01:31,650 --> 01:01:35,610
这个就是需要根据这个时候来具体的做一下

997
01:01:35,640 --> 01:01:37,290
开厂做一下就好

998
01:01:38,250 --> 01:01:40,860
然后后面的话就是还有一些内容

999
01:01:41,190 --> 01:01:44,220
还有一些之前会的一些内容，我们就不多说了

1000
01:01:44,340 --> 01:01:47,820
就是呃呃，说一下这些主要的一些东西对

1001
01:01:48,270 --> 01:01:53,580
然后呢，这里面正常来说呢，还有一个字段是殷代是ID

1002
01:01:53,850 --> 01:01:56,250
就是说，假如说你这个舌头是

1003
01:01:56,640 --> 01:02:01,950
走了，所以它实际上会有一个一个的第一个阶段，然后里面会有一个一带似的

1004
01:02:01,955 --> 01:02:07,260
和ID ID的值，然后通过这个ID的值可以知道啊，这个ID这样哪个所以？

1005
01:02:08,070 --> 01:02:12,810
对呀，这个索引是把他的哪些字段啊，就能知道这个，所以我是不是走得正？

1006
01:02:13,140 --> 01:02:16,050
啊，那这里面有我们没有原谅的，ID这个词

1007
01:02:16,680 --> 01:02:21,600
那没有的时候呢，但是有两种情况，一个是啊，他就是没有作业

1008
01:02:22,440 --> 01:02:26,250
还有一种情况就是这个时候他走了主见

1009
01:02:26,310 --> 01:02:29,040
因为主见就是

1010
01:02:29,730 --> 01:02:35,040
因为主见，她跟k是有一些相关性的，假如说他走了，组件

1011
01:02:35,045 --> 01:02:37,680
实际上，这里面也是也是不会

1012
01:02:37,685 --> 01:02:39,990
呃，显示出那个银泰来电了

1013
01:02:42,420 --> 01:02:44,100
好再继续

1014
01:02:45,030 --> 01:02:50,340
好，然后我们上面做了一些监控写日志怎么的？

1015
01:02:50,345 --> 01:02:54,390
这些信息的一个分析啊，我们后面呢？

1016
01:02:54,660 --> 01:02:59,130
继续在对这个时候来看一下它的执行计划是怎么样的？

1017
01:03:00,090 --> 01:03:02,490
啊，这里我们看了一下他的执行计划

1018
01:03:02,580 --> 01:03:07,140
可以看到，执行计划，她这个执行计划呢？是走一个推钩子看

1019
01:03:07,680 --> 01:03:12,990
也就是说，它这里面是没有走，所以呢，然后大家可以看到他他就是看里面的认识的没有

1020
01:03:12,995 --> 01:03:14,160
要那个

1021
01:03:14,700 --> 01:03:18,690
啊，这个认识是一个正无穷和负无穷到正无穷的一个区间

1022
01:03:18,695 --> 01:03:24,000
假如说是走个组件的话，这里面实践是一个小的区间，比如说是1到12

1023
01:03:24,005 --> 01:03:24,660
累了

1024
01:03:25,110 --> 01:03:28,350
也就是说，他这个肯定是没有走出去

1025
01:03:28,470 --> 01:03:31,650
还有就是说他这里面没有一代是磁卡

1026
01:03:31,740 --> 01:03:35,460
没有，现在才看呢，也就是说它是没有走20岁

1027
01:03:35,490 --> 01:03:39,660
啊，那这个综合起来看啊，这个时候我就走了一个小圈表

1028
01:03:40,200 --> 01:03:45,510
然后这里面呢，然后有一些同学可能会有一些疑问，既然他这个

1029
01:03:45,515 --> 01:03:47,760
条件里面有一个态，不断

1030
01:03:47,940 --> 01:03:51,090
那他为什么不能走太远了，这个索引呢？

1031
01:03:52,470 --> 01:03:57,780
这里面有一个问题，就是说它这个走到哪个？所以它是根据统计信息呢？

1032
01:03:58,080 --> 01:03:58,770
算了

1033
01:04:02,190 --> 01:04:07,500
然后因为太姥自断了它是一个范围查询，而且这个范围大家可以看

1034
01:04:07,505 --> 01:04:08,880
她是比较大的

1035
01:04:08,970 --> 01:04:12,210
当这个范围比较大的时候，实际上

1036
01:04:12,540 --> 01:04:16,110
就是在某些场景，他还不如做一个

1037
01:04:16,140 --> 01:04:18,750
全抄表的一个操作，然后去

1038
01:04:18,840 --> 01:04:21,690
啊对这个数据来过滤

1039
01:04:22,500 --> 01:04:23,640
所以呢？

1040
01:04:23,670 --> 01:04:28,980
这个锁，所以呢，这个里面的这个QQ就是他组织一个访谈表还没有走

1041
01:04:28,985 --> 01:04:31,290
我不知道的这个范围查询

1042
01:04:33,060 --> 01:04:37,230
然后这个呢，我们根据这个具体的调控呢，就可以看到

1043
01:04:37,260 --> 01:04:39,990
他这个思考加一个

1044
01:04:40,260 --> 01:04:43,080
胖了三，然后按着探母

1045
01:04:43,170 --> 01:04:46,170
这个两个字段的一个索引，然后就能

1046
01:04:46,710 --> 01:04:49,230
更更更更效率的

1047
01:04:49,410 --> 01:04:51,960
查查询查询出这个数据

1048
01:04:52,290 --> 01:04:54,600
对，然后我们大家提醒了一下

1049
01:04:55,440 --> 01:05:00,750
好，上面上面我们将大概得出了一个结果，我们需要

1050
01:05:00,755 --> 01:05:04,980
加重的一个康姆三，然后和父母这两个字段的时候联合，所以

1051
01:05:05,070 --> 01:05:07,770
我们这边加入之后呢，大家可以看到

1052
01:05:09,060 --> 01:05:14,370
加了之后，执行计划呢，是这个样子的，然后里面是有一个一代粉上班

1053
01:05:14,970 --> 01:05:17,520
然后音那个词看到里面是有一个

1054
01:05:17,700 --> 01:05:23,010
音音这样子，然后毛毛好，后面是两个阶段，就是看上面没有人看，就说这两个字

1055
01:05:23,015 --> 01:05:24,600
阶段啊，他走专业了

1056
01:05:25,170 --> 01:05:28,110
然后还可以看到这个，后面还有一个位置

1057
01:05:28,230 --> 01:05:31,740
而论证呢，里面是有一个范围，就是说

1058
01:05:32,340 --> 01:05:34,110
考了个三点

1059
01:05:34,350 --> 01:05:36,360
抗日山，然后探母

1060
01:05:36,480 --> 01:05:37,980
就是看了

1061
01:05:40,110 --> 01:05:45,420
一个下线，然后到康乐的三按照贪污的一个上线这么一个吧！

1062
01:05:45,480 --> 01:05:46,560
去吃饭呗！

1063
01:05:47,310 --> 01:05:50,820
然后根据这个范围呢，然后就可以拿到

1064
01:05:50,850 --> 01:05:54,000
对应的那个k就是

1065
01:05:54,150 --> 01:05:55,860
真正数据的这个k

1066
01:05:56,010 --> 01:06:01,320
因为那个索引的数据和数据和因为所有的数据和表的数据

1067
01:06:01,325 --> 01:06:03,480
也实际上存放是

1068
01:06:03,570 --> 01:06:04,680
有些区别的

1069
01:06:04,740 --> 01:06:07,740
然后呢，根据这个索引的数据呢，能拿到

1070
01:06:08,040 --> 01:06:13,350
真正的表数据的这个k然后根据这个key再去做一个退出来看

1071
01:06:13,355 --> 01:06:17,610
执法这个可以对应的这些数据，然后就能把这个

1072
01:06:17,910 --> 01:06:20,760
符合条件的这个数据都能拿得出来的

1073
01:06:21,450 --> 01:06:23,760
所以你可以看到啊！

1074
01:06:24,480 --> 01:06:28,620
这样这个所以之后我们执行这个查询，然后这个产品的速度就很快了

1075
01:06:30,930 --> 01:06:36,240
然后我们再做一下补充，就是还有一个第二部分，然后

1076
01:06:36,245 --> 01:06:38,700
这里面呢，我们主要是讲一下

1077
01:06:39,360 --> 01:06:43,560
常见的日志的错误以及常见的监控的错误

1078
01:06:43,920 --> 01:06:45,180
啊这些

1079
01:06:45,690 --> 01:06:51,000
就是这些日子的错误和监控的错误呢，虽然说有的时候可能会报一些安若惠

1080
01:06:51,005 --> 01:06:52,140
就是一个蜗牛

1081
01:06:52,230 --> 01:06:53,220
但是

1082
01:06:53,310 --> 01:06:54,630
他不一定

1083
01:06:54,840 --> 01:06:55,680
就是

1084
01:06:55,685 --> 01:06:58,380
不一定真的就对疾病有

1085
01:06:58,560 --> 01:07:01,860
啊，多么多么大的影响，比如说可能

1086
01:07:01,890 --> 01:07:07,200
产生了一个调度，然后发生了一个日志有一个啊，咋地点儿说是

1087
01:07:07,290 --> 01:07:12,600
结婚里面，比如说呢他厉害那这个时候呢，可能他是属于一个正常的速度，实际上这里的

1088
01:07:12,605 --> 01:07:13,680
这没有影响

1089
01:07:14,340 --> 01:07:18,450
啊，我们这里面呢？是列举了常见的几个错误

1090
01:07:18,630 --> 01:07:19,410
是

1091
01:07:19,590 --> 01:07:21,000
啊，这里面就

1092
01:07:21,180 --> 01:07:24,120
我们上面是一个一个来说

1093
01:07:24,630 --> 01:07:28,380
啊，差多少，然后差多少呢？这个是指

1094
01:07:29,280 --> 01:07:34,590
他这个之间呢，他是有一个现场来做通信的，专门做一个通信的一个

1095
01:07:34,595 --> 01:07:37,350
操作，然后这个现场的事情啊，然后就知道

1096
01:07:37,830 --> 01:07:41,250
然后他既然是做一个通信的，对吧？

1097
01:07:41,520 --> 01:07:46,650
然后它是有个队列的通讯，他是有着对应的，就是说它不能无限

1098
01:07:47,100 --> 01:07:49,740
不能无上限的去接受这个消息

1099
01:07:50,580 --> 01:07:55,170
然后当你这个队列放满之后，比如说这个对联就是举个例子

1100
01:07:55,470 --> 01:07:58,890
举个列子，这个对练，比如说只能接受1000个请求

1101
01:07:59,010 --> 01:08:04,320
那你1000块钱就满了啊，剩下的一千零一千多1000多啊，管它过来那你就说

1102
01:08:04,325 --> 01:08:08,070
这个年纪出了，所以就会产生一个差不多的的一个监控

1103
01:08:08,190 --> 01:08:11,610
然后插到树里面的纸呢？实际上都是溢出的这些

1104
01:08:12,210 --> 01:08:15,030
溢出的这些信息的一个情况

1105
01:08:15,720 --> 01:08:21,030
然后当出现这个情况呢？然后可能就是说啊，然后他死到这个现场，太忙了

1106
01:08:22,020 --> 01:08:24,300
然后还有就是说可能

1107
01:08:25,140 --> 01:08:26,850
激情的一些

1108
01:08:27,000 --> 01:08:29,160
消息太多了，成语消息太多了

1109
01:08:29,700 --> 01:08:33,090
然后这个消息包括微整的数量太多了

1110
01:08:33,095 --> 01:08:38,400
然后还包括写入，或者说是啊，主要是写入吧，然后

1111
01:08:38,405 --> 01:08:39,690
写入的

1112
01:08:40,650 --> 01:08:44,910
数据太多了然后也会导致那个消息的一个基础

1113
01:08:45,840 --> 01:08:48,660
然后这个在老版本是

1114
01:08:48,960 --> 01:08:49,800
啊？

1115
01:08:50,820 --> 01:08:53,850
就是压力比较大的时候会

1116
01:08:53,910 --> 01:08:59,220
呃，相对容易一点，出现这个情况，然后在新版本的，因为我们

1117
01:08:59,225 --> 01:09:02,520
把这次当这个单线程，改成了一个多现场

1118
01:09:03,180 --> 01:09:08,490
所以就是啊，大家也可以根据实际情况去调整这个现场的一个

1119
01:09:09,060 --> 01:09:10,020
的数量

1120
01:09:10,050 --> 01:09:13,890
所以呢，在新版本基本上不太会出现这个情况

1121
01:09:14,850 --> 01:09:16,470
让大家了解一下就可以了

1122
01:09:18,060 --> 01:09:23,370
没有so ri胖的非绿色，然后这个呢也是说他嘿威之间就是多个才可以

1123
01:09:23,375 --> 01:09:25,830
之间也是会有一个风险

1124
01:09:26,520 --> 01:09:29,040
会有一个信息的一个交互

1125
01:09:29,100 --> 01:09:34,170
对当网络出现问题，或者说是网络出现抖动的时候

1126
01:09:34,200 --> 01:09:38,640
消息我发过去了，就出现一个失败的一个监控信息

1127
01:09:38,790 --> 01:09:42,090
然后这个监控信息呢？里面会包含

1128
01:09:42,750 --> 01:09:48,060
我这个数据是从哪个台kv发到哪个台kv的？然后这个星期是

1129
01:09:48,065 --> 01:09:49,080
是失败的

1130
01:09:49,770 --> 01:09:53,850
当比如说我们激情，比如说这五个太太对他说12345

1131
01:09:54,450 --> 01:09:56,130
开k5，有没有题了？

1132
01:09:56,160 --> 01:09:57,720
他因为他是

1133
01:09:58,080 --> 01:10:01,230
因为它可以之间是两两交互来

1134
01:10:01,590 --> 01:10:02,910
发这个消息的

1135
01:10:02,915 --> 01:10:04,290
那这个时候呢？

1136
01:10:04,470 --> 01:10:09,780
因为它分为1234都会给她微博发这个消息，而他用V5也会给其他

1137
01:10:09,785 --> 01:10:15,090
再查查这个时候，因为团这边网络有问题了，好，其他的节点就他为伍

1138
01:10:15,390 --> 01:10:17,160
发这个消息啊，韩国去了

1139
01:10:17,220 --> 01:10:22,530
就会出现很多的成为唯一，然后到他人的，然后这个消息是

1140
01:10:22,650 --> 01:10:27,510
缺点了然后他就给200他给五年级谁的，然后当看到这种

1141
01:10:27,900 --> 01:10:30,330
规律的消息的时候就可以

1142
01:10:30,960 --> 01:10:36,270
所以一个判断，也就是说啊，都是翻到台v V5这个消息失败了，你就说他跟

1143
01:10:36,275 --> 01:10:37,470
15，这个节点

1144
01:10:38,070 --> 01:10:43,380
好，或者说是网络出问题了，或者说是这个服务出问题了然后大家就是根据

1145
01:10:44,010 --> 01:10:48,120
这个牌子根据这个推断的结果，然后去这个节点上面

1146
01:10:48,540 --> 01:10:53,580
然后看些，比如说人质了然后或者说是分析一些系统情况

1147
01:10:53,970 --> 01:10:57,840
然后来确认一下这个是不是真的有这个问题？

1148
01:10:59,640 --> 01:11:01,980
啊然后下面是？

1149
01:11:02,430 --> 01:11:07,500
Skv就是里面比较常见的一个问题就是骗人的

1150
01:11:07,950 --> 01:11:10,710
然后这个问题呢在？

1151
01:11:11,070 --> 01:11:14,220
就是数量很少的情况下

1152
01:11:14,310 --> 01:11:16,020
实际上是一个

1153
01:11:16,620 --> 01:11:19,590
啊，属于一个正常的一个调度

1154
01:11:19,650 --> 01:11:23,310
就是说我们数据在kv里面是

1155
01:11:23,730 --> 01:11:27,120
而瑞智来分的，然后对着呢，他又根据

1156
01:11:27,150 --> 01:11:30,030
那个绕的协议来选举

1157
01:11:30,300 --> 01:11:35,610
这是每一个每一个为人的各入口都会跟这个大的协议来选出一个力量

1158
01:11:35,940 --> 01:11:41,160
那随着业务的一些变更，比如说写入，比如说查询

1159
01:11:41,520 --> 01:11:45,510
然后里面都会伴随着一些调度，就是你写入的时候好

1160
01:11:45,750 --> 01:11:49,500
然后出去数据多了，出去多了之后他就会

1161
01:11:49,770 --> 01:11:55,080
根据这个数据的分布情况，去安乐死这个数据，然后可能比如说

1162
01:11:55,085 --> 01:12:00,390
这个一数据写出来了啊，刚来死亡了，他这个二二的这个时候产生的时候，数据的调度

1163
01:12:00,395 --> 01:12:01,770
这个角度之后呢？

1164
01:12:01,830 --> 01:12:04,560
就会伴随着有一些厉害一些，这样的情况

1165
01:12:05,430 --> 01:12:06,990
还有就是说

1166
01:12:07,290 --> 01:12:10,320
比如说查询查询，虽然说是

1167
01:12:10,380 --> 01:12:13,890
没有数据的写入，但是呢，因为你查询多了

1168
01:12:14,190 --> 01:12:17,370
查询过之后，难免可能会有一些

1169
01:12:17,610 --> 01:12:21,960
查查询的一个不均衡的一个情况，比如说退出一个号，查询压力大

1170
01:12:22,110 --> 01:12:26,550
那这个时候呢，我们就会系统内部这个是不需要人员参与的

1171
01:12:26,640 --> 01:12:29,910
就是系统内部会尝试吧，他可以以上面的低调

1172
01:12:30,300 --> 01:12:31,860
要做到其他几点开门？

1173
01:12:31,865 --> 01:12:37,170
那这个时候呢，就相当于达到一个相对的一个平衡，就是多个节点的请求多个

1174
01:12:37,175 --> 01:12:38,340
几点的400？

1175
01:12:38,400 --> 01:12:40,410
作文节点的资源消耗

1176
01:12:40,415 --> 01:12:44,730
都是达到了一个相对的平衡，不至于产生是我们从小人

1177
01:12:45,720 --> 01:12:51,030
然后下面就是在他的位日志里面，我们也可以看到一个片儿，一个最低的那一个

1178
01:12:51,035 --> 01:12:52,500
的这个信息

1179
01:12:54,750 --> 01:13:00,060
就是大家可以根据这个现象来具体的他们如果是

1180
01:13:00,065 --> 01:13:03,360
数量很少，这样就是不用关系，如果数量很多

1181
01:13:03,960 --> 01:13:09,270
可能就是几百好几千那这个时候可能是集群发生了一些问题

1182
01:13:09,840 --> 01:13:11,910
比如说有几点关掉了？

1183
01:13:11,970 --> 01:13:13,050
比如说

1184
01:13:13,080 --> 01:13:18,390
有节点，然后太忙了，导致这个节点接受不了其他节目一些消息，然后说

1185
01:13:18,395 --> 01:13:23,700
所以会产生一些也是绿地已经超时了然后发现一个成立选举

1186
01:13:24,060 --> 01:13:26,100
啊，这个情况就是需要

1187
01:13:27,540 --> 01:13:29,880
根据具体的情况来具体分析一下

1188
01:13:31,530 --> 01:13:36,840
然后死掉了然后这个问题呢，一般也是不用太关注，就是说

1189
01:13:45,540 --> 01:13:48,990
比如说他弟弟这边的区域，房子太贵的时候好

1190
01:13:49,350 --> 01:13:54,660
然后就是说泰迪比这边本地呢会缓存一份这个数据

1191
01:13:54,665 --> 01:13:56,070
导游路由信息

1192
01:13:56,220 --> 01:13:58,950
这个路由信息就是指他会

1193
01:13:59,220 --> 01:14:00,780
啊记录

1194
01:14:01,260 --> 01:14:04,740
当然，身份内存里面的她会记录你这个

1195
01:14:05,130 --> 01:14:10,440
数据会会一是在哪个才是这个上面数据块二是现在哪个才是最上面的？然后我反问的

1196
01:14:10,445 --> 01:14:11,430
再访

1197
01:14:11,435 --> 01:14:13,530
应该去哪个节点去访问这个数据？

1198
01:14:14,070 --> 01:14:16,620
好，然后因为他记住这个信息

1199
01:14:16,740 --> 01:14:22,050
然后她他就去这边好，它是一个全球的时候，他会优先根据这个内存里面的这个

1200
01:14:22,055 --> 01:14:24,630
都有个信息去拿这个数据

1201
01:14:24,990 --> 01:14:27,120
假如说这个数据呢？

1202
01:14:27,870 --> 01:14:33,180
开开开这边也发生了一个变更好调头走了，或者说是珠子类的一些情况

1203
01:14:33,185 --> 01:14:34,560
不是分裂了，对吧？

1204
01:14:34,830 --> 01:14:36,690
去房子的时候发现没有了

1205
01:14:36,695 --> 01:14:37,980
也就是说

1206
01:14:39,030 --> 01:14:40,890
也就说他拿着这个信息了

1207
01:14:40,950 --> 01:14:44,820
拿到这个信息了之后，然后他认为这边会给他一个

1208
01:14:44,850 --> 01:14:46,320
返回的一个

1209
01:14:47,040 --> 01:14:52,350
将最后的一个信息可以理解了，这个交互的信息就会告诉他们的，这个路由器过期了

1210
01:14:52,355 --> 01:14:53,280
然后

1211
01:14:53,550 --> 01:14:56,130
啊诸如此类一个信息吧，然后呢？

1212
01:14:56,640 --> 01:15:01,950
它就会根据它可以这边反馈的信息就更新自己的一个本地，等于数据或者

1213
01:15:01,955 --> 01:15:02,700
说

1214
01:15:03,330 --> 01:15:07,350
或者说，假如说p aa QQ这边没有给他返回给？

1215
01:15:08,010 --> 01:15:12,930
最新的这个数据，然后他就会去PT这边再拉一份最新的数据的一个

1216
01:15:13,560 --> 01:15:17,310
呃，路由信息来再去做这个法则的一个请求

1217
01:15:18,060 --> 01:15:19,650
啊，这个是

1218
01:15:19,680 --> 01:15:21,930
啊，所以4500的这个

1219
01:15:22,200 --> 01:15:23,640
信息的一个含义

1220
01:15:25,710 --> 01:15:31,020
好好像就是往下还有一个改，他们是他们出色的，然后这个问题

1221
01:15:31,025 --> 01:15:32,100
行了吧？

1222
01:15:33,000 --> 01:15:37,560
一般就是出现在泰利b和霹雳之间，然后因为

1223
01:15:37,565 --> 01:15:38,910
因为他的病

1224
01:15:39,180 --> 01:15:44,100
就是做一些深刻的时候呢，就是做一些刺客，往往是参加检查之类的

1225
01:15:44,460 --> 01:15:47,580
他会去霹雳这边去哪一个天才？

1226
01:15:47,670 --> 01:15:50,940
这个tx o就是就是我们平常说的时间说

1227
01:15:51,390 --> 01:15:56,700
然后去根据这个时间穿的，然后再对这个事物

1228
01:15:57,150 --> 01:16:02,340
所以先判断，就是说判断这个事物啊，是不是冲突然后之类的一些情况？

1229
01:16:02,370 --> 01:16:05,640
好，那假如说我们霹雳

1230
01:16:06,180 --> 01:16:09,510
就是她对地区霹雳这边去替他收啊

1231
01:16:10,530 --> 01:16:11,520
这个时间

1232
01:16:12,360 --> 01:16:13,140
很久

1233
01:16:13,530 --> 01:16:17,640
比如说那个100的画面，200，多画面，比如说是明白的，画面等等等

1234
01:16:18,060 --> 01:16:19,770
那这个时候

1235
01:16:20,070 --> 01:16:22,500
就会影响你的整个的一个业务

1236
01:16:22,620 --> 01:16:26,730
因为你拿天书已经办了，那你再把这个

1237
01:16:26,735 --> 01:16:32,040
就拿回来之后再把这个请求再发到他跟人家这边再去做一些查询作息

1238
01:16:32,045 --> 01:16:36,480
做一些写入党的写操作，那这个整个的链路就会好擅长

1239
01:16:37,230 --> 01:16:42,330
就会产生一些办法，选好这个时候是假如说这个干

1240
01:16:43,290 --> 01:16:48,600
那个该他们死那个兔子肉比较多的时候，那这个时候需要检查一下集群内些

1241
01:16:48,605 --> 01:16:49,620
一个状态

1242
01:16:50,040 --> 01:16:55,350
然后重点需要查一下好看的一批一批地之间的一个网络的延迟

1243
01:16:56,010 --> 01:16:57,600
好霹雳这边

1244
01:16:57,690 --> 01:17:00,330
呃，霹雳这边的话主要是看抖的年代了

1245
01:17:00,360 --> 01:17:02,760
看看被丽丽的节点的一个

1246
01:17:02,765 --> 01:17:06,690
机器的复杂情况是不是最近又特别高？是不是热度特别高？

1247
01:17:06,870 --> 01:17:08,790
是不是磁盘哎哟？特别高

1248
01:17:09,270 --> 01:17:11,460
假如说这些

1249
01:17:12,720 --> 01:17:13,800
机器

1250
01:17:13,890 --> 01:17:19,200
就是一些机器的一些复杂，导致他可以用这边卡了啊不是

1251
01:17:19,205 --> 01:17:20,940
导致霹雳这边卡了

1252
01:17:20,945 --> 01:17:26,250
然后就会也会产生这个盖特，他们上午兔子肉的一个情情况

1253
01:17:26,400 --> 01:17:30,240
当然，开心率这边也是第一次，她对这边卡了，实际上也会

1254
01:17:30,420 --> 01:17:31,980
呃，发生这么一个情况

1255
01:17:33,510 --> 01:17:38,820
然后我们下面是有一个监控，然后通过这些监控呢，大家就可以判断出

1256
01:17:39,540 --> 01:17:44,340
那是啊，是不是这个概念的？还是这块儿？

1257
01:17:44,940 --> 01:17:47,970
已经产生了一个比较高的一个颜值

1258
01:17:50,580 --> 01:17:51,600
然后

1259
01:17:51,630 --> 01:17:55,110
安慰了吧？然后安慰了吧这个

1260
01:17:55,470 --> 01:17:56,460
啊？

1261
01:17:57,930 --> 01:18:03,240
如果是比较少的情况，就是出现次数很少，实际上

1262
01:18:03,270 --> 01:18:06,120
也也不用特别多的

1263
01:18:06,510 --> 01:18:08,130
呃，纠结这个问题

1264
01:18:08,430 --> 01:18:13,230
然后假如说是发生特别多，就是假如说好业务反几个事故

1265
01:18:13,680 --> 01:18:17,010
八个月过了，失败了再发现了然后又让他们过失败

1266
01:18:17,370 --> 01:18:21,450
而这时候就需要查一下啊，一般时候呢，是因为？

1267
01:18:21,570 --> 01:18:24,660
啊，一般省那是因为这个瑞典呢？

1268
01:18:24,720 --> 01:18:28,440
就是这个瑞珍的入口，应该他是多个副本的，他没有选主力

1269
01:18:28,800 --> 01:18:32,370
没有选修课的呢，也是有多个情况，一个是

1270
01:18:32,430 --> 01:18:33,540
啊调度了

1271
01:18:33,630 --> 01:18:34,920
你打调度了

1272
01:18:34,925 --> 01:18:37,860
或者说是力点钞超时了重新选举还没选出

1273
01:18:37,950 --> 01:18:39,270
那你访问的时候

1274
01:18:39,360 --> 01:18:44,670
因为读写都是走路的了那你这时候访问的时候好好这个数据实际上是安慰了保护胃

1275
01:18:45,630 --> 01:18:49,530
如果是这个重新选举的情况，好像是

1276
01:18:49,800 --> 01:18:51,660
再重试一下，有空天呐

1277
01:18:51,810 --> 01:18:57,120
当然，他实际内部也有考试，也可能不用，也可能还没有返回到呃

1278
01:18:57,125 --> 01:19:00,900
户里面还没有返回到业务测，然后他就已经处理成功了

1279
01:19:02,010 --> 01:19:02,940
然后

1280
01:19:03,180 --> 01:19:08,490
比较差的情况就是说它内部充实又成功了，我发给用户错了然后又错了

1281
01:19:08,910 --> 01:19:10,860
发生了一个安慰，也不可用

1282
01:19:11,340 --> 01:19:14,040
对，这是一个啊！

1283
01:19:15,870 --> 01:19:21,180
看到这个消息之后，就会感觉到比较紧张，感觉可能这个

1284
01:19:21,185 --> 01:19:26,490
这就是帮了啊，可能是不能用了，对然后这个啊，不一定就是

1285
01:19:26,495 --> 01:19:29,520
不可能是某个点，然后才是一些

1286
01:19:29,670 --> 01:19:34,200
比如说挂在那里，我才可以，然后穿上一个程序选举，然后实际上是

1287
01:19:34,590 --> 01:19:35,880
被卡这么

1288
01:19:36,510 --> 01:19:37,500
啊？

1289
01:19:37,980 --> 01:19:40,110
就是秒进人嘛，会卡几秒

1290
01:19:40,170 --> 01:19:45,480
这个时候，然后再过过这么几秒钟后，然后时间就会恢复正常，然后还有一个情况

1291
01:19:45,485 --> 01:19:47,610
是比较严重的，就是说

1292
01:19:48,030 --> 01:19:49,860
挂了多数副本

1293
01:19:50,730 --> 01:19:53,760
比如说集群本身就三个数字

1294
01:19:54,150 --> 01:19:56,250
就是当时我默认就是三个副本

1295
01:19:56,430 --> 01:19:58,530
你可能逛了两个菜，特别好

1296
01:19:59,040 --> 01:20:03,000
挂了两个台科院之后，然后你可能这两个摊位上面

1297
01:20:03,005 --> 01:20:08,310
有一些数据的多数副本，那你假如说业务上面再去访问这部分数据

1298
01:20:08,315 --> 01:20:11,610
因为那些机器里面只剩一个副本

1299
01:20:11,970 --> 01:20:15,090
那这一个副本是属于少数的少数里的

1300
01:20:15,300 --> 01:20:17,130
那这个时候就是

1301
01:20:17,370 --> 01:20:22,230
不管怎么访问？不管怎么强求？不管这个城市全都是安慰我不会用的

1302
01:20:22,235 --> 01:20:24,990
这个时候就需要做一些修复的一些操作

1303
01:20:25,500 --> 01:20:30,810
如果这如果挂掉的多数的书本，有能起来的好起到

1304
01:20:30,815 --> 01:20:34,440
多数的时候，比如说三个月的好像挂了两个数字，然后起来

1305
01:20:34,530 --> 01:20:36,600
啊，那这个时候时间又不正常

1306
01:20:37,470 --> 01:20:38,820
然后就是

1307
01:20:38,970 --> 01:20:44,280
能恢复的时候经常恢复，如果是实在这个机器好比如说吃太稍微了两个时代

1308
01:20:44,285 --> 01:20:45,030
多少啊？

1309
01:20:45,060 --> 01:20:48,270
好恢复不了然后我们这边也有办法

1310
01:20:48,690 --> 01:20:53,790
就是来恢复，就是根据一个副本来恢复这个数据，当然因为是一个副本

1311
01:20:54,120 --> 01:20:57,900
他不一定是最新的，可能是数据有一些就是

1312
01:20:58,470 --> 01:21:02,040
就是尽量把这个风险降低到最小

1313
01:21:05,970 --> 01:21:06,630
啊？

1314
01:21:06,840 --> 01:21:10,230
还有CCTV3，我太胖了嘛，然后这个台面

1315
01:21:10,235 --> 01:21:11,880
他有意思，老太骂他们

1316
01:21:13,020 --> 01:21:17,730
也是，一般是两个情况，一个是集群的负载太高了

1317
01:21:18,240 --> 01:21:23,520
而这个的本质原因本质原因就是说他可以and必须去

1318
01:21:23,550 --> 01:21:26,940
向它可以为发起一个请求做查询插座

1319
01:21:26,970 --> 01:21:28,080
结束啦，等等

1320
01:21:28,680 --> 01:21:32,340
他对于这么长时间没有响应，然后所以会产生一个产品

1321
01:21:32,700 --> 01:21:34,710
啊，这个时候呢，一般是两个情况

1322
01:21:35,460 --> 01:21:37,650
一个是即使负债太高了

1323
01:21:37,710 --> 01:21:39,060
还KTV这边

1324
01:21:39,570 --> 01:21:44,880
资源都用的，比如说很高，可能录得到了几十几本啊？

1325
01:21:44,885 --> 01:21:49,290
这个时候，他可以选择过来了，就全场太大了，还有一个情况是

1326
01:21:49,890 --> 01:21:51,960
他特别挂了，多祝福吧

1327
01:21:52,110 --> 01:21:57,420
报了多数副本，然后他这边呢，因为是挂了多少书本，然后他因为没有力的嘛也

1328
01:21:57,425 --> 01:21:58,890
是实时的

1329
01:21:59,010 --> 01:22:02,310
也有想要，然后也会成立一个，还有一些生活才能好

1330
01:22:04,830 --> 01:22:05,970
如果是

1331
01:22:07,020 --> 01:22:07,920
看看了

1332
01:22:08,460 --> 01:22:12,240
就是如果是激情，特别傻嘛，这个场景

1333
01:22:12,360 --> 01:22:13,710
然后大家就需要

1334
01:22:13,890 --> 01:22:19,200
根据前面提到的一些知识点来判断一下，这个剧情为什么这么？

1335
01:22:20,280 --> 01:22:25,440
是有热点，还是说有一些所以还是说有一些查询走错了，所以

1336
01:22:25,470 --> 01:22:26,310
导致

1337
01:22:26,550 --> 01:22:28,800
这个整个剧情的开销比较大

1338
01:22:28,950 --> 01:22:30,450
然后就是

1339
01:22:30,480 --> 01:22:35,160
针对性的去做一些优化啊，假如说是真的挂科数出版

1340
01:22:36,660 --> 01:22:38,580
啊，我们这个时候就需要

1341
01:22:38,670 --> 01:22:43,980
能恢复恢复能恢复，就把这个观察复诊恢复起来不能

1342
01:22:43,985 --> 01:22:45,450
恢复根据

1343
01:22:45,930 --> 01:22:49,830
啊，通过一些工具来把这个数据拿给他

1344
01:22:50,460 --> 01:22:54,090
把这个给选来给她修复，当然数据可能会有些优势

1345
01:22:56,760 --> 01:23:02,070
好，然后今天的内容，然后就是这些，然后希望对大家

1346
01:23:02,580 --> 01:23:07,890
以后使用它利弊，或者说是其他一些类似的一些架构的

1347
01:23:07,895 --> 01:23:08,490
对啊！

1348
01:23:08,670 --> 01:23:10,680
产品上面会有一些帮助

1349
01:23:10,685 --> 01:23:11,760
学习能量

1350
01:23:16,470 --> 01:23:17,070
我不知道

