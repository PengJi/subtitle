1
00:00:00,030 --> 00:00:05,340
嗯嗯嗯嗯嗯

2
00:00:12,510 --> 00:00:13,800
大家好

3
00:00:13,805 --> 00:00:17,460
今天这个讲座，给大家介绍一下泰迪被整体架构

4
00:00:17,760 --> 00:00:20,130
我是平台部的技术VP胜利

5
00:00:20,940 --> 00:00:24,360
今天这个门课程会从这样几方面进行介绍

6
00:00:24,365 --> 00:00:26,190
包括他的是什么？

7
00:00:26,195 --> 00:00:27,600
他是一个什么样数据库？

8
00:00:27,605 --> 00:00:31,200
他的一些整体的架构，它的分层的情况

9
00:00:31,500 --> 00:00:35,370
然后以及它最重要的两层，一个是我们的分布式存储引擎

10
00:00:35,400 --> 00:00:38,040
另外一个就是分布式的CD已经泰迪b

11
00:00:38,310 --> 00:00:39,540
介绍这样几个要点

12
00:00:41,160 --> 00:00:43,500
首先我们来看看利弊是什么？

13
00:00:44,640 --> 00:00:46,920
一句话来说，她对币是一个

14
00:00:47,040 --> 00:00:48,810
分布式的强音是

15
00:00:48,960 --> 00:00:51,420
具备水平扩展的关系型数据库

16
00:00:52,380 --> 00:00:56,250
然后整个这个数据库是我们平台公司自主研发

17
00:00:56,520 --> 00:01:00,270
完全开源的这么一个数据库，然后我们在设计这个数据库

18
00:01:01,110 --> 00:01:02,820
聚焦在这样四个特性

19
00:01:03,090 --> 00:01:04,140
第一个水平扩展

20
00:01:04,590 --> 00:01:08,160
作为一个分布数据或者说那么水平扩展的我们也是他的

21
00:01:08,165 --> 00:01:09,690
最基本最基本的一个能力

22
00:01:09,840 --> 00:01:12,960
就是当你的整个的数据库的能力不够

23
00:01:13,050 --> 00:01:18,360
我们可以通过简单的加机器去帮你把，无论是存储的能力还是计算能力进行水平扩展

24
00:01:19,050 --> 00:01:20,160
第二点，高考用

25
00:01:20,220 --> 00:01:25,530
因为它的币作为分数数据过来说，他的提升的节点可能会非常多，可能有

26
00:01:26,400 --> 00:01:28,170
几十个甚至上百个节点

27
00:01:28,380 --> 00:01:33,690
那么，这些节点的异常情况的失效，或者是正常情况下，我们对集群做骨正升级

28
00:01:34,230 --> 00:01:38,250
那么，我们都要解决少量节点失效的这样一个高可用问题

29
00:01:38,370 --> 00:01:40,530
当然，同时我们还能够去做

30
00:01:40,710 --> 00:01:45,720
跨数据中心的这个这个这个高可用，比如说一个数据中心挂掉之后

31
00:01:45,750 --> 00:01:48,150
还有另外的适应症能够去提供服务

32
00:01:48,900 --> 00:01:51,030
第三点是事务，acd，事务

33
00:01:51,360 --> 00:01:56,670
其实很多分布式的存储存储系统，比如说a是类似这样的系统，他们通过放弃c口

34
00:01:57,060 --> 00:01:58,770
放弃事物

35
00:01:58,980 --> 00:02:02,640
获得更简单的这种模型，然后来实现更好的水平扩展能力

36
00:02:02,910 --> 00:02:03,900
三七十

37
00:02:03,960 --> 00:02:08,430
在严肃的生产环境中特别是一些和交易和合性探险中

38
00:02:08,435 --> 00:02:10,950
事务费是非常重要的一个特性

39
00:02:11,100 --> 00:02:11,700
对

40
00:02:11,730 --> 00:02:15,780
大家看到很多在AC被此基础上做事物的解决方案

41
00:02:16,680 --> 00:02:21,990
所以我们也提供了事务知识，而且我们认为事物这个如果存储不解决

42
00:02:22,470 --> 00:02:25,950
那么外面的业务，或者你外面的这个中间件就要去解决

43
00:02:26,010 --> 00:02:26,610
他们

44
00:02:26,820 --> 00:02:31,410
外面的业务去解决或者是中国外国的解决，它很难做的高校

45
00:02:32,730 --> 00:02:33,720
最后就是随口

46
00:02:33,750 --> 00:02:38,160
我们最终是提供一个关系数据库，我们希望提供完整的最后支持

47
00:02:38,460 --> 00:02:40,050
然后让用户的

48
00:02:40,110 --> 00:02:41,760
业务学起来就很简单

49
00:02:43,920 --> 00:02:46,170
呃，这张图是太利率整体架构

50
00:02:46,350 --> 00:02:51,660
或者说我们是泰迪一批家族的这种架构，包括里面不止包括太币的数据库内核也包括

51
00:02:51,665 --> 00:02:56,970
我的一些周边工具，比如说导入导出工具边那个向下和同步的工具

52
00:02:57,330 --> 00:03:01,470
还有我们的这整个运维，还有我们的大数据解决方案台词吧！

53
00:03:01,530 --> 00:03:02,760
给我们的监控

54
00:03:02,820 --> 00:03:08,130
监控组组建普罗米修斯等等这样一些东西其实是很复杂的一个系统

55
00:03:08,880 --> 00:03:14,190
那么，作为一个这么复杂的分数系统，除了数据库内核之外，还有这么多组建，那么我们

56
00:03:14,195 --> 00:03:14,850
文

57
00:03:14,855 --> 00:03:19,080
如何去简化他们的运维，我们提供两种方式，第一种方式通过

58
00:03:19,085 --> 00:03:24,390
安息国的方式就是直接在裸机上去部署，这个我们整套服务

59
00:03:24,750 --> 00:03:26,340
可能不是我们的周边工具

60
00:03:26,730 --> 00:03:31,110
另一方面呢，就是我们写也提供了，可以把他支持我们希望

61
00:03:31,170 --> 00:03:34,080
通过kk is这样一套

62
00:03:34,290 --> 00:03:39,600
弹性扩展的管理整个这个下面物理资源的方案能够简化我们

63
00:03:39,605 --> 00:03:40,800
这样一套

64
00:03:40,950 --> 00:03:43,410
复杂的分数数据或者运维和使用

65
00:03:43,950 --> 00:03:48,600
对，这就是我们整个kk白色方的一个核心核心的这个架构，这是我们在

66
00:03:48,720 --> 00:03:49,800
黑白色中

67
00:03:50,070 --> 00:03:52,710
实现了我们自己的这个这个熬不一致

68
00:03:52,740 --> 00:03:53,400
然后

69
00:03:53,610 --> 00:03:55,110
帮助可以把s

70
00:03:55,290 --> 00:04:00,150
理解如何管理调度运维这么一个复杂的分数式数据库

71
00:04:00,420 --> 00:04:02,370
后后面会有专门的课程来进

72
00:04:03,930 --> 00:04:07,530
对于我们回到最本质的最咸，最核心的数据库内核

73
00:04:07,980 --> 00:04:10,200
来看，那怎么叫过去简单很多？

74
00:04:10,410 --> 00:04:11,190
我们

75
00:04:11,520 --> 00:04:15,090
我们可以看到，这我们数据库内核大概分了两个

76
00:04:15,300 --> 00:04:19,650
分了两层关键组件，第一层是叫泰利必

77
00:04:19,890 --> 00:04:20,730
是在这里

78
00:04:21,000 --> 00:04:23,070
是一个无状态的计算引擎

79
00:04:23,160 --> 00:04:26,430
她来和外面的应用后端

80
00:04:26,580 --> 00:04:27,810
做做交互

81
00:04:27,840 --> 00:04:29,670
交通的收购协议一

82
00:04:29,700 --> 00:04:33,870
接收物品的请求，那对外面的应用来说，看到的就是一个买CC

83
00:04:34,920 --> 00:04:35,790
然后

84
00:04:35,880 --> 00:04:37,800
下面是我们的太卑微

85
00:04:37,805 --> 00:04:43,020
的这个分布式，但事物的存储，运行还是一个退休辞职旅行

86
00:04:43,230 --> 00:04:47,880
然后他是真正的把数据存进去，然后进行数据存储的视频或者

87
00:04:47,885 --> 00:04:53,190
以及接收由上面CC和引擎发下来的这个计算请求从本地拿趣

88
00:04:53,195 --> 00:04:55,650
数据之后，再把计算结果返回给上层

89
00:04:56,190 --> 00:04:59,280
然后所以右边是屁屁是我们的集训管理节点

90
00:04:59,340 --> 00:05:01,890
我们叫它普利斯们就普林斯顿的专门

91
00:05:02,130 --> 00:05:06,450
那么，它主要是存储存储态度积极的信息，就是每天数据到底在哪里？

92
00:05:06,600 --> 00:05:09,930
以及这整个儿开学军训的负载进行进行调度

93
00:05:10,710 --> 00:05:16,020
我们可以简单的理解为pd和TK v构成一个分布式能够水平扩展

94
00:05:16,025 --> 00:05:16,620
啊？

95
00:05:16,740 --> 00:05:18,120
762行

96
00:05:18,270 --> 00:05:21,510
然后上面它的必是整个我们这个数据库的这个计算层

97
00:05:22,020 --> 00:05:24,210
这样一个两层的一个角度看

98
00:05:24,330 --> 00:05:27,600
我们后面的这个介绍也会这样两层

99
00:05:27,630 --> 00:05:28,920
来就来进行

100
00:05:30,060 --> 00:05:34,950
对，首先我们看这个泰迪b的存储引擎，也就是开个车去

101
00:05:35,400 --> 00:05:39,660
那么我们先我们会了解到这个村庄形式怎么做的？包括他们每一层

102
00:05:39,665 --> 00:05:41,670
是如何实现的，他的数据

103
00:05:41,700 --> 00:05:45,900
最终存在这次必中，然后通过上面的袜子进行水平扩展

104
00:05:46,050 --> 00:05:47,730
和数据的强制复制

105
00:05:47,790 --> 00:05:53,100
然后我们还还会介绍我们如何对数据库进行自动的水平扩展，比如说

106
00:05:53,280 --> 00:05:54,870
我加一个空气点之后

107
00:05:54,930 --> 00:05:56,010
如何将？

108
00:05:56,015 --> 00:05:58,620
现有的基本上数据均衡过去

109
00:05:58,860 --> 00:06:02,340
伤害就是我们的集训，整个钓鱼啊，还有分之15这些东西

110
00:06:03,210 --> 00:06:08,520
OK，首先看看泰森为的风是一个太太太太为这个分布式存储运行态

111
00:06:08,525 --> 00:06:12,240
他的他的整体价格我们是一个高度分层的价格

112
00:06:12,660 --> 00:06:14,220
呃，主要是在这四层

113
00:06:14,520 --> 00:06:19,410
最下面一层这个搂口啤白这个所谓的所有人也支持这是

114
00:06:19,470 --> 00:06:24,780
这个本地的存运行，也就我们用的mcc币，它是一个由facebook开发的一个

115
00:06:24,785 --> 00:06:30,090
一个嵌入式的ky类型，她的速度非常快，而且他有一些原则的掰扯

116
00:06:30,095 --> 00:06:32,460
Y的多线程版本本身这样一些

117
00:06:32,610 --> 00:06:33,630
比较好的特性

118
00:06:34,410 --> 00:06:36,480
然后这样势必会把数据

119
00:06:37,170 --> 00:06:42,480
存在邦帮助taka把数据存在磁盘上，那么它是一个嵌入式的存运行

120
00:06:42,750 --> 00:06:44,190
但她并不能

121
00:06:44,370 --> 00:06:49,680
保证你这个高可用，所以我们上面做了，让她当当当当当，单个键，实际上是要如何？

122
00:06:50,250 --> 00:06:53,580
如何还有其他副本，而且是强制的副本

123
00:06:53,640 --> 00:06:57,120
当然，这上面是mcc和四五等等提供更高级的功能

124
00:06:57,780 --> 00:06:59,280
大家可以看到，我们是一个

125
00:06:59,285 --> 00:07:01,260
强你是一个

126
00:07:01,265 --> 00:07:06,060
分布式的一些层的价格高度分层就每一层和每一层之间的耦合比较薄

127
00:07:06,090 --> 00:07:08,250
那么，这样做的好处是

128
00:07:08,340 --> 00:07:09,990
一方面，我们可以

129
00:07:10,710 --> 00:07:14,580
对每一层进行单独的优化，让每一层这个

130
00:07:15,120 --> 00:07:20,430
自己只要保证对外接口雨雨雨是不变的啊，可以每一层内部做的

131
00:07:20,435 --> 00:07:22,590
类型优化，另一方面呢？

132
00:07:22,620 --> 00:07:27,930
也可以把单独某一层抽掉，然后我可以换成其他的组件，或者是说换成一个

133
00:07:27,935 --> 00:07:30,210
万科的组建利用我做测试

134
00:07:31,470 --> 00:07:34,800
然后另外我们一个特点就是我们直接依赖于本地文件系

135
00:07:34,860 --> 00:07:36,390
不依赖于分布式的系统

136
00:07:36,450 --> 00:07:38,910
这这样整个系统的延迟会更低

137
00:07:41,610 --> 00:07:42,240
OK

138
00:07:42,870 --> 00:07:44,190
首先我们看

139
00:07:44,400 --> 00:07:47,310
这个数据是如何落地和容灾的？

140
00:07:47,490 --> 00:07:51,900
我们的数据落地是存储在尼克斯的实力之前，一批批地讲到

141
00:07:52,110 --> 00:07:53,070
但是

142
00:07:54,030 --> 00:07:59,340
存到了c，实际中，它是帮你把数据录到硬盘上，但是你这个这个硬盘坏掉，或者是这个机

143
00:07:59,345 --> 00:08:00,780
整个坏掉的时候

144
00:08:00,960 --> 00:08:03,600
那么你这个这块数据也丢掉了

145
00:08:04,050 --> 00:08:04,800
所以

146
00:08:05,040 --> 00:08:10,350
这样私密帮我们解决了数据的落地问题，并没有帮我解决书籍的高圆圆问题，也就是如

147
00:08:10,355 --> 00:08:11,790
或许做容灾

148
00:08:11,910 --> 00:08:13,710
那么要进行容灾

149
00:08:14,250 --> 00:08:15,600
就一定要有多副本

150
00:08:15,930 --> 00:08:21,240
那么，每个副本直接就是你一个副本，这个损失掉之后还有其他的副本能够

151
00:08:21,245 --> 00:08:22,470
过去提供服务

152
00:08:22,710 --> 00:08:27,390
那么，要做多副本就要选一种副本之间的数据复制方案

153
00:08:27,690 --> 00:08:33,000
而且你要想实现这个更好的，现在你可能需要实现的是强一致的

154
00:08:33,005 --> 00:08:38,310
复制就是一个副本，丢掉之后，我的数据还是不会丢，还是一致的，能对外表现出一致

155
00:08:38,315 --> 00:08:39,930
一致的，这个这个数据

156
00:08:40,110 --> 00:08:41,670
所以我们选择肉粉

157
00:08:41,850 --> 00:08:43,110
我们通过飘浮着

158
00:08:43,115 --> 00:08:43,830
在

159
00:08:43,950 --> 00:08:49,260
这个数数据的多个副本之间做强一致，且高效的复制

160
00:08:50,310 --> 00:08:55,620
知道不就是我们一个非常核心的这么一个模块，然后它有几个特性，后面后面会用到锁

161
00:08:56,220 --> 00:08:58,020
第一，他是一个

162
00:08:58,620 --> 00:09:01,770
多数派写入的这么一个一个协议是什么意思呢？

163
00:09:01,890 --> 00:09:06,570
就是假设我这个月负责将数据复制三份

164
00:09:06,780 --> 00:09:12,090
那么，每次写入，我都要保证至少两个副本型成功才对客户端返回成功

165
00:09:12,095 --> 00:09:17,400
但这样即使任何一个副本丢掉，我依然有至少一个副本是有最新数据

166
00:09:17,940 --> 00:09:21,360
所以数据是不会丢，所以它能实现强烈的复制

167
00:09:21,990 --> 00:09:27,300
然后第二，他是一个强力的协协议什么意思呢？就是所有的数据的写入和读取都是从

168
00:09:27,305 --> 00:09:31,170
可理解来进行，就是我多个副本，只有一个是理解这样两个

169
00:09:31,380 --> 00:09:34,950
那么，通过理解去进行读写，这是绕到一个约束

170
00:09:35,490 --> 00:09:38,670
当然，我们后面还会做更多的优化，比如说我们一些

171
00:09:38,700 --> 00:09:43,320
一些毒情仇，我们可以通过佛法而来进行，然后去减少延迟

172
00:09:45,270 --> 00:09:49,470
还有整个这个丽刚才提到了点儿了，这两个角色，但是两个角色的

173
00:09:49,500 --> 00:09:52,680
这个这个位置不是固定的，比如说我有三个副本

174
00:09:52,710 --> 00:09:53,790
那么水藏里面

175
00:09:54,030 --> 00:09:55,620
然后另外谁让冯仑

176
00:09:55,625 --> 00:09:57,990
这个是动态进行的就是

177
00:09:58,200 --> 00:10:00,900
她整容让我有一套成员选举的算法

178
00:10:01,050 --> 00:10:03,330
那么，这套成员所有的算法会保证

179
00:10:03,510 --> 00:10:07,170
理解在失效的情况下发了，而能够自动进行选举

180
00:10:07,200 --> 00:10:12,510
选出一个有最新数据节点节点当做新的理解决定提供服务，所以中国的服务我们呢？

181
00:10:12,515 --> 00:10:17,190
实现数据的容灾以及高考用，就是单个副本掉了之后

182
00:10:17,195 --> 00:10:20,850
会有机会有另外一个副本变成理解，继续对外提供服务

183
00:10:21,780 --> 00:10:27,090
然后整个这个，刚才提到成员变更，无论是这个，这个利的部落角色的变换

184
00:10:27,630 --> 00:10:32,940
这个无论是这个正常情况常情况呢？这个变化比如说一个副本就离这个丢掉了

185
00:10:32,945 --> 00:10:34,710
发展会自动的全球成功

186
00:10:34,740 --> 00:10:40,050
或者说，我们通过一些调度的方式主动让你进行里的和后面角色的迁移

187
00:10:40,260 --> 00:10:43,440
或者我建一个新的副本或者是删除一个分

188
00:10:43,470 --> 00:10:46,410
这些都是让让做成员变更的一部分

189
00:10:46,560 --> 00:10:48,030
我们后面的数据的

190
00:10:48,390 --> 00:10:49,440
是不均衡

191
00:10:49,980 --> 00:10:52,770
以及数据复本位副本的约束

192
00:10:52,890 --> 00:10:55,320
包括我现在三本以后想别人五副本

193
00:10:55,500 --> 00:10:58,290
或者我现在是三副本，我丢掉了一个几点之？

194
00:10:58,410 --> 00:11:01,860
提交了一个实力之后，我可能确实有些数据缺了一个副本

195
00:11:01,865 --> 00:11:03,870
那么，都是通过这些成员变更算法

196
00:11:03,875 --> 00:11:07,200
来补齐数据来实现这个以及实验负载均衡

197
00:11:08,010 --> 00:11:08,640
OK

198
00:11:08,820 --> 00:11:12,480
有了大部分之后，我们就可以将数据在不同的

199
00:11:12,510 --> 00:11:13,410
机器

200
00:11:13,740 --> 00:11:16,710
或者机架或者数据中心之间进行

201
00:11:16,715 --> 00:11:17,520
分布

202
00:11:17,550 --> 00:11:18,630
以复制

203
00:11:18,930 --> 00:11:21,240
对，这是一个非常非常核心的概念

204
00:11:22,110 --> 00:11:22,770
怎么？

205
00:11:22,920 --> 00:11:24,810
这里我们只是说

206
00:11:24,815 --> 00:11:26,730
一份数据如何有多个副本？

207
00:11:27,300 --> 00:11:27,900
对吧？

208
00:11:27,930 --> 00:11:30,000
然后我们如何去将

209
00:11:30,180 --> 00:11:33,750
整个一个一个大量的数据打伞在一个

210
00:11:33,755 --> 00:11:36,510
多台机械基础上，这是第二个问题

211
00:11:36,930 --> 00:11:40,650
对丈夫的解决了，是一份数据，如何做强制的多副本？

212
00:11:40,890 --> 00:11:43,860
那么，下一步我们要看如何进行真正的分布式

213
00:11:44,100 --> 00:11:45,450
那你要做分布式

214
00:11:46,770 --> 00:11:48,990
需要做第一个角色就是

215
00:11:49,080 --> 00:11:51,120
我们如何将数据进行切片？

216
00:11:51,150 --> 00:11:56,460
切片之后，只有这这是一些切片才可能将不同切片的副本掉落在不同位置上来实习

217
00:11:56,465 --> 00:11:57,990
现在其实上的分布

218
00:11:58,290 --> 00:12:01,680
他们要进行分片，就要选择一个数据分片算法

219
00:12:02,250 --> 00:12:04,560
常用的两种，一种是基于这个

220
00:12:05,010 --> 00:12:06,060
哈西的分辨

221
00:12:06,750 --> 00:12:11,130
就是我来了个t然后我自己做一个哈希值，然后决定

222
00:12:11,160 --> 00:12:13,740
决定把他放在哪个哪个哪个那个分片上？

223
00:12:13,920 --> 00:12:15,060
但这样的话

224
00:12:15,600 --> 00:12:20,550
我们是很难去做一段范围内的事，因为被打死了，整个军训

225
00:12:20,850 --> 00:12:25,500
但是因为我们最终想做一个c口数据库，那么我们一定要支持这种

226
00:12:26,010 --> 00:12:27,030
随口的

227
00:12:27,150 --> 00:12:32,460
这种种连续范围的sky，比如说我要去通过索引，过了一段数据等等，或者是全嫂全秒数

228
00:12:32,670 --> 00:12:34,380
所以我们选择的是

229
00:12:34,385 --> 00:12:35,280
鲫鱼

230
00:12:36,300 --> 00:12:37,530
举一个例子分辨

231
00:12:37,950 --> 00:12:38,880
然后

232
00:12:38,940 --> 00:12:41,070
我们这里用的车顺着碎片

233
00:12:41,100 --> 00:12:42,480
就是我们家

234
00:12:42,840 --> 00:12:47,610
这个态度中的这个替代空间，这个逻辑空间看成一个有序的外部

235
00:12:47,850 --> 00:12:48,600
什么？

236
00:12:48,660 --> 00:12:51,810
从无穷小到无穷大，有这样两个特殊的体外的

237
00:12:52,080 --> 00:12:55,650
OK然后我们将这个占空间进行切分

238
00:12:55,950 --> 00:12:57,330
然后切成一段一段

239
00:12:57,510 --> 00:13:00,480
然后每一段有一个人信息就是他的

240
00:13:00,570 --> 00:13:02,220
起始和结束的t

241
00:13:02,250 --> 00:13:05,790
当然，这个替考呗，我们的证明的T恤外面都是卖的数组

242
00:13:06,060 --> 00:13:11,130
这个替代有序是指按照但是数组的比特币，是比较是有序的

243
00:13:12,600 --> 00:13:15,600
然后这个切片是如何划分的呢？

244
00:13:15,750 --> 00:13:17,850
我们的切片，实际上是

245
00:13:17,910 --> 00:13:23,220
根据一个睿智里面存放的所有的t和歪歪的

246
00:13:23,225 --> 00:13:24,450
大小加起来

247
00:13:24,540 --> 00:13:26,460
知道那个字结束

248
00:13:26,490 --> 00:13:28,260
以这个为分配的依据

249
00:13:28,320 --> 00:13:29,940
当一个睿智的

250
00:13:30,030 --> 00:13:33,510
数据超过某个阈值的时候，我们没认识96张

251
00:13:33,720 --> 00:13:36,030
就会进行一个自动的分切分

252
00:13:36,090 --> 00:13:37,140
变成多个分辨

253
00:13:39,030 --> 00:13:39,930
这是一个例子

254
00:13:41,370 --> 00:13:43,980
首先，我们假设我们有一个有一个威震

255
00:13:44,580 --> 00:13:48,750
所以他一开始可能我们整个军训开始比较比较空，那么只有一个位置

256
00:13:48,810 --> 00:13:50,580
大概说这个数据不断写入

257
00:13:50,670 --> 00:13:52,800
这个是智能数据不断变多

258
00:13:52,830 --> 00:13:55,590
那么这个时候我们就会进行一个自动的拆

259
00:13:55,980 --> 00:13:57,810
就将数据从

260
00:13:57,815 --> 00:13:58,680
一个睿智

261
00:13:59,070 --> 00:14:00,450
拆成两回去

262
00:14:01,020 --> 00:14:05,730
注意，这里是一个原信息的拆分，而不是真实物理信息的拆分

263
00:14:06,510 --> 00:14:09,450
这里说的原信息是指前面一直提到的

264
00:14:09,455 --> 00:14:13,320
这个一个真正的四川的，可以按这样一个卖的对她

265
00:14:13,860 --> 00:14:14,670
然后

266
00:14:15,480 --> 00:14:20,790
这个锐圳上这个认证的副本的数据还是存在这两个位置的副本的数据

267
00:14:20,795 --> 00:14:25,620
还是存在一个态度，实际中的那个貌似必中，他物理上还是存在一起

268
00:14:25,710 --> 00:14:28,290
只是我们在逻辑上本来变成了两个瑞典人

269
00:14:28,680 --> 00:14:30,810
只有我们在第一部

270
00:14:31,410 --> 00:14:36,720
在逻辑上将它变成不同的实力，这个原型进行管理，我们下一步如何采访的物理？

271
00:14:36,725 --> 00:14:37,650
你想把她

272
00:14:37,655 --> 00:14:39,180
走到不同的节点上

273
00:14:39,330 --> 00:14:42,780
然后才能才能实现下一步物理上的分分离和调度

274
00:14:43,440 --> 00:14:46,260
然后整个这个分裂呢，是在自动的不断的进

275
00:14:46,290 --> 00:14:47,190
然后

276
00:14:47,370 --> 00:14:49,650
这边不需要去做任何操作

277
00:14:50,700 --> 00:14:51,330
好累

278
00:14:52,110 --> 00:14:57,420
分裂之后，我们怎么实现使用扩展就是我分裂之后？数据还是在一台机上，只是他是

279
00:14:57,425 --> 00:14:59,100
通过两个圆形因管理

280
00:14:59,520 --> 00:15:00,660
下面这只是个例子

281
00:15:00,840 --> 00:15:03,240
比如说我想有这样一个集训，有四个节点

282
00:15:03,540 --> 00:15:05,070
然后这四个几点呢？

283
00:15:05,220 --> 00:15:05,940
有

284
00:15:06,270 --> 00:15:10,800
其中有一个几点可能数量比较多？他存了三个三块数据，他可能快满了

285
00:15:11,340 --> 00:15:16,650
他们我们加一个空的节点进去看看，如提升如何？是如何来？

286
00:15:16,655 --> 00:15:18,090
实现这个水平扩展

287
00:15:18,510 --> 00:15:19,380
干嘛？

288
00:15:19,710 --> 00:15:25,020
我们假设我们集团决定将这个ri陈姨的这个副本那么

289
00:15:25,025 --> 00:15:27,180
红色的三个是瑞典一的三个副本

290
00:15:27,240 --> 00:15:30,480
然后我们决定将这个副本调度在调度新的节点上去

291
00:15:30,485 --> 00:15:35,430
然后将它删掉，那么这个时候他就实现了这个这个数据的使用或者

292
00:15:35,610 --> 00:15:38,250
那么我们第一步可能是先将这个

293
00:15:38,640 --> 00:15:43,950
这个这个副本的利润角色牵引走，因为读写作走了点儿，我们把它牵走之后

294
00:15:43,980 --> 00:15:45,720
后续的调度就不会

295
00:15:46,020 --> 00:15:47,520
不会影响先生的业务

296
00:15:48,480 --> 00:15:51,390
那么，第一步可能是将它的离的角色穿针一

297
00:15:51,660 --> 00:15:54,060
第二步，我们通过软件的的这个加副本

298
00:15:54,300 --> 00:15:59,610
这样一个命令，这个命令算法在这边去加一个副本，然后这里会向从离了这边去了

299
00:15:59,615 --> 00:16:00,600
拿一个全量

300
00:16:00,930 --> 00:16:03,570
全能的镜像这块，这小片数据全能的镜像

301
00:16:03,600 --> 00:16:08,130
然后然后再用当时他全量的时候那个乱服落落的拼音辆去拉，后面增量

302
00:16:08,340 --> 00:16:10,080
然后再把它增量追上

303
00:16:10,290 --> 00:16:10,920
OK

304
00:16:11,130 --> 00:16:12,120
然后下一步

305
00:16:12,930 --> 00:16:15,060
我们再把这个这个副本删除掉

306
00:16:15,150 --> 00:16:16,350
这个时候就会

307
00:16:16,830 --> 00:16:22,140
这个这个时候就实现了，在物理上是通过加粉粉和删粉的，这样的命令实现逻辑

308
00:16:22,145 --> 00:16:25,110
上的一个数据从这边迁移到这边来

309
00:16:25,680 --> 00:16:28,110
整个过程是在动态不断的进行

310
00:16:29,640 --> 00:16:34,560
我可以那么这整个过程，整个这个负载均衡的过程是谁来控制？

311
00:16:34,770 --> 00:16:39,000
是由集训中一个叫pd的角色，刚才提到了这个普锐斯的他专门

312
00:16:39,030 --> 00:16:39,810
还进行

313
00:16:40,050 --> 00:16:45,360
它存储了集训的袁西西，就是他知道整个集群的状态，整个军训有多少副本，有多少这个？

314
00:16:45,630 --> 00:16:48,390
每个专业都有副本，怎么也在哪里？实际一点

315
00:16:48,720 --> 00:16:50,850
那么，所有的违规节点

316
00:16:51,360 --> 00:16:56,670
以及所有的真正理解的，都会不断地向通过新的消息向屁屁汇报自己的最新的状态

317
00:16:56,850 --> 00:17:01,920
那么，pp就能获取一个全局的信息就是整个基金是什么样的一个状态？

318
00:17:02,220 --> 00:17:06,510
呃，每个节点上尊重空间剩余多少CPU使用率内存使用量

319
00:17:06,515 --> 00:17:08,580
读写流量等等这些信息

320
00:17:08,820 --> 00:17:10,350
有了这些全部信息之后

321
00:17:11,190 --> 00:17:13,620
弟弟在根据管理员配置的策略

322
00:17:13,680 --> 00:17:15,210
这个策略可能是

323
00:17:15,300 --> 00:17:18,780
副本的数量的限制，比如说每一块数据有多有几个副本？

324
00:17:19,080 --> 00:17:24,390
可能是调度速度的限制，比如说我进行力量迁移，我进行强提到这个加速的

325
00:17:24,395 --> 00:17:25,380
删除本科

326
00:17:25,385 --> 00:17:26,160
数组

327
00:17:26,280 --> 00:17:27,270
有没有上线？

328
00:17:27,660 --> 00:17:32,970
因为所有的迁移调度都是由代价开销的消耗CPU，网络内存等等这些资源

329
00:17:33,240 --> 00:17:34,260
那我们需要

330
00:17:34,500 --> 00:17:37,230
我们为了避免这现象的影响，没有一个

331
00:17:37,320 --> 00:17:40,290
速度的限制，但我们这个没韧性是比较保守的

332
00:17:40,350 --> 00:17:44,010
如果你并不是现象的话，那你可以把这个速度调高

333
00:17:44,130 --> 00:17:44,730
我

334
00:17:45,390 --> 00:17:46,620
具体就根据

335
00:17:46,800 --> 00:17:48,000
一方面根据

336
00:17:48,060 --> 00:17:49,590
这个军训员信息

337
00:17:49,680 --> 00:17:52,260
一方面，根据管理员的配置策略

338
00:17:52,530 --> 00:17:54,390
然后生成调度命令

339
00:17:54,600 --> 00:17:56,070
下发到太规矩矩

340
00:17:56,220 --> 00:17:59,040
然后对整个集群的负载均衡进行调度

341
00:17:59,190 --> 00:17:59,790
对

342
00:17:59,880 --> 00:18:01,530
弟弟是整个军训的大脑

343
00:18:03,660 --> 00:18:04,320
OK

344
00:18:06,030 --> 00:18:11,340
然后我们前面提到了这个，让他提到了霹雳，提高负载均衡

345
00:18:11,345 --> 00:18:12,690
提到这个水平扩展

346
00:18:12,780 --> 00:18:16,020
哎呀，之之前我们看到了如何做一个

347
00:18:16,050 --> 00:18:20,970
分布分布式的ta的存储引擎，能够自己做负载均衡，能够扩展到多少g？

348
00:18:21,300 --> 00:18:24,840
那最终我们我们需要提供业务知识，我们这个业务知识是

349
00:18:24,990 --> 00:18:27,960
是在这个台kv就是辞职也行，这方面做的

350
00:18:28,170 --> 00:18:31,170
我们的数模型是那个姑姑的宝宝类的

351
00:18:31,410 --> 00:18:33,750
这是一个分布式物的一个解决方案

352
00:18:34,080 --> 00:18:34,980
然后

353
00:18:35,070 --> 00:18:39,480
这是一个去中心，基本上去中心化两天的提交

354
00:18:39,870 --> 00:18:40,740
然后

355
00:18:40,770 --> 00:18:46,080
为什么我们说他是基本上就是硬化呢？因为我们其实还有个优点就是事物的这个TF

356
00:18:46,110 --> 00:18:50,910
没有一个中一个，每个市我们会生成一个版本号，那这个版本号是有一个

357
00:18:51,270 --> 00:18:54,870
中心节点来生产的这个中心点就是霹雳资讯

358
00:18:54,990 --> 00:18:56,160
去去去去离这儿

359
00:18:56,165 --> 00:18:57,870
对生产这个时间出来

360
00:18:57,990 --> 00:19:01,710
然后当霹雳的理解这个出现问题的时候

361
00:19:01,715 --> 00:19:05,670
包包会自动变成新的理解，111，然后对外提供替孩子的服务

362
00:19:05,700 --> 00:19:07,920
可以整个这个实验室服务

363
00:19:08,040 --> 00:19:11,220
是一个比较轻量级的操作，那么这个时候对

364
00:19:11,460 --> 00:19:13,320
这个对性能影响并不大

365
00:19:13,710 --> 00:19:14,340
不会

366
00:19:14,940 --> 00:19:16,140
所以它是一个去

367
00:19:16,290 --> 00:19:20,280
这是一个单位，然后其他的是管理器啊，所以这些状态全都是

368
00:19:20,310 --> 00:19:21,690
打伞的，怎么去欣赏？

369
00:19:22,200 --> 00:19:27,330
两个另外提一点就是我们现在的30之前只支持了，关索就是我们的

370
00:19:27,360 --> 00:19:29,310
事物的所得模型是在

371
00:19:29,400 --> 00:19:34,710
我们不会在事物的运行过程中去上真正去上锁，而是在事务提交过程中

372
00:19:34,715 --> 00:19:35,970
去检查所得冲突

373
00:19:36,030 --> 00:19:37,530
所以这种乐观锁的冒险

374
00:19:37,560 --> 00:19:38,730
这种情况下

375
00:19:38,880 --> 00:19:44,190
在一些冲突比较高的产品中，并并不太适应，然后我们在看看这个30的问题中做了

376
00:19:44,310 --> 00:19:45,990
提供了悲观锁，这样一个特性

377
00:19:46,260 --> 00:19:50,130
其实我们提供了真正的是像类似于买水口澳客这种

378
00:19:50,135 --> 00:19:52,920
在数据的进行期间，就去将

379
00:19:52,925 --> 00:19:53,940
这样的数据

380
00:19:53,945 --> 00:19:54,750
上厕所

381
00:19:54,870 --> 00:20:00,180
然后这个你能够保证你锁住数据，你能够在提交的时候就是大概这个东西

382
00:20:00,185 --> 00:20:01,050
要成功

383
00:20:01,440 --> 00:20:05,730
然后另外我们先默认的隔离级别是那个style少的s雷神

384
00:20:06,210 --> 00:20:08,370
现在目前只是这种隔离级别

385
00:20:08,850 --> 00:20:14,160
然后这篇论文这这个这个文档是那个呱呱呱的一个的一个实现，大家有兴趣运费

386
00:20:14,165 --> 00:20:14,970
你看一下

387
00:20:17,370 --> 00:20:17,970
不会

388
00:20:18,030 --> 00:20:23,340
我们到现在我们就有了一个分布式大事物的拜拜六层运气

389
00:20:23,345 --> 00:20:24,840
那么它整个价格是？

390
00:20:25,110 --> 00:20:27,030
整个整个价格是这样子就是

391
00:20:27,120 --> 00:20:29,130
我们有很多太太和实力

392
00:20:29,135 --> 00:20:32,730
每个实际上面会存放一些睿睿的副本

393
00:20:32,820 --> 00:20:38,130
然后不同实际上的这个多个副本构成的复购用户相互之间进行这个数据的复制

394
00:20:38,310 --> 00:20:41,640
数据里的里的写出去，然后你的在数据给发了

395
00:20:41,910 --> 00:20:47,220
然后被历来是或是掌握整个均匀信息，然后最近进行进行进行进行

396
00:20:47,225 --> 00:20:48,480
进行四点进行调度

397
00:20:48,540 --> 00:20:50,970
同时，外面这个客户端方面，它可以进行的时

398
00:20:50,975 --> 00:20:55,890
第一次访问时候会去问人力要一下这个我要访问的屁到底在哪里来的？

399
00:20:55,980 --> 00:20:58,350
就是这个p所对应的微信是谁？

400
00:20:58,470 --> 00:21:00,660
然后他就追陈丽这在哪里？然后

401
00:21:00,810 --> 00:21:04,500
第二次访问呢，就会把这个吸毒性化妆术，就不需要每次

402
00:21:04,560 --> 00:21:08,040
不会每次访问才可以进去，都会去问pd 1路由信息

403
00:21:08,880 --> 00:21:09,480
会

404
00:21:10,080 --> 00:21:12,390
然后这是我们心里已经有了一个

405
00:21:12,420 --> 00:21:16,830
这样一个分布式的一个一个但事物的特别的从引擎

406
00:21:17,520 --> 00:21:19,050
为下一步我们看一下

407
00:21:19,290 --> 00:21:20,370
如何在？

408
00:21:20,580 --> 00:21:21,690
这个

409
00:21:21,870 --> 00:21:27,090
这个词这样一个替班的村，你想做做这个水果就是做一个水果引擎

410
00:21:27,630 --> 00:21:29,850
对，我们会了解一些我们这个水库中的价格

411
00:21:30,180 --> 00:21:32,850
二月处理的一个核心流程是什么样子的？

412
00:21:33,210 --> 00:21:36,120
以及我们整个这个分布式计算的一个框架

413
00:21:39,210 --> 00:21:42,960
呃，要在一个分布式的kv

414
00:21:43,140 --> 00:21:45,330
仅仅上座关系模型

415
00:21:45,450 --> 00:21:47,190
上网做的第一步就是

416
00:21:47,195 --> 00:21:52,500
想一下，如何将这些关系模型中的一些一些东西转换成pp白酒，比如说如何将？

417
00:21:52,505 --> 00:21:53,310
啊宝宝

418
00:21:53,340 --> 00:21:55,350
我将数据如何将所以

419
00:21:55,770 --> 00:21:56,940
755进去

420
00:21:57,240 --> 00:22:00,720
然后另外我们还提供一这个这个全军，所以

421
00:22:00,725 --> 00:22:02,610
然后其实用权体制性的，所以

422
00:22:03,000 --> 00:22:05,460
然后这是很多业务所依赖的

423
00:22:06,030 --> 00:22:09,030
然后另外呢，我们因为我们要做一个

424
00:22:09,150 --> 00:22:14,460
一个真正的这个让业务能够更便于使用的这样一个数据库，所以我们的

425
00:22:14,730 --> 00:22:18,300
结构功能需要做非常完善，包包括特别是我们来提供

426
00:22:18,360 --> 00:22:23,370
随口协议的内容还有很多买，除了这个标准，随口的功能之外，我们还提供

427
00:22:23,400 --> 00:22:26,370
很多和买水购方言相关的一些业务功能

428
00:22:27,060 --> 00:22:30,600
然后大家最后因为我们是一个分布式，就是我们会从人海

429
00:22:30,750 --> 00:22:31,770
什么？

430
00:22:31,950 --> 00:22:37,260
用户将数据存进来之后，他也希望能够直接在你数据库里面进行数据的使用

431
00:22:37,500 --> 00:22:38,340
所以

432
00:22:38,345 --> 00:22:43,650
我们除了这个简单的o tt p的这个复杂之外，我们也希望能够支持在大数据量上

433
00:22:43,655 --> 00:22:44,550
啊进行

434
00:22:44,670 --> 00:22:46,740
进行气量及分析这么一种复杂

435
00:22:47,250 --> 00:22:49,920
是一个APP的这样一个数据库

436
00:22:50,880 --> 00:22:53,820
然后我们的这个问题，那就要只要这样这样

437
00:22:55,230 --> 00:22:56,820
然后这是我们整合的价格

438
00:22:57,090 --> 00:22:58,740
这种门锁管理的架构

439
00:22:59,430 --> 00:23:00,540
大家可以看到

440
00:23:01,140 --> 00:23:05,070
这边是我们的协议层，就是外面的各种

441
00:23:05,220 --> 00:23:06,840
我们这个就是在

442
00:23:06,960 --> 00:23:12,270
和外面的客户端通讯通过买社会协议通讯，然后做协议的解析，包括协议的编码器

443
00:23:12,275 --> 00:23:12,900
什么？

444
00:23:13,170 --> 00:23:15,660
然后拿到协议中的这个请求

445
00:23:15,840 --> 00:23:19,020
然后再扔到我们这个门口的核心这一场

446
00:23:19,080 --> 00:23:21,120
这层是处理说以后的

447
00:23:21,210 --> 00:23:22,710
真正处理这个国际

448
00:23:22,740 --> 00:23:27,540
包括做语法解析，包括做这个验证，包括做优化，包括做秩序

449
00:23:27,690 --> 00:23:29,880
但我们这边还包括有一个权限

450
00:23:30,060 --> 00:23:32,280
比如说这个西瓜管理

451
00:23:32,940 --> 00:23:35,190
有个统计信息，比如说各种

452
00:23:35,195 --> 00:23:36,720
各种这个后台的任务

453
00:23:36,810 --> 00:23:37,560
干嘛？

454
00:23:37,565 --> 00:23:41,700
这是我们完全实现的一个一个完整的CC引擎

455
00:23:42,210 --> 00:23:44,820
对对对，这个就是写一些容师非常优秀的

456
00:23:46,170 --> 00:23:47,820
那么一条随口

457
00:23:47,940 --> 00:23:52,230
在核心这块在我们的随口的核心层，需要经过哪些处理？

458
00:23:53,610 --> 00:23:54,570
首先

459
00:23:54,990 --> 00:23:58,620
一条c扣的文本，我们拿到它的文本之后，我们首先

460
00:23:58,680 --> 00:23:59,610
通过

461
00:23:59,700 --> 00:24:00,960
语法的解析

462
00:24:01,020 --> 00:24:04,830
我怕死，将一条c扣文本转成一个结构化数据

463
00:24:04,835 --> 00:24:06,930
抽象语法树，这叫AST

464
00:24:07,140 --> 00:24:07,740
我可以

465
00:24:07,745 --> 00:24:13,050
比如这个月辞职后呢，我们在将这棵语法树进行一些数据，一些语法语意的校验

466
00:24:13,290 --> 00:24:15,780
一些合法性验证啊，等等，这些这些工作

467
00:24:15,930 --> 00:24:17,400
然后扔给我们净化器

468
00:24:18,570 --> 00:24:23,880
然后拿我们就拿到一个这个第一部经过逻辑逻辑化，逻辑化就是

469
00:24:23,885 --> 00:24:25,710
通过一些数学上等待变化

470
00:24:25,715 --> 00:24:27,120
使得这条

471
00:24:27,270 --> 00:24:28,350
随口的

472
00:24:28,380 --> 00:24:31,980
这个在变化之前变化之后的语义等价但

473
00:24:32,250 --> 00:24:35,400
但这个这个代价计算更小，比如说

474
00:24:35,580 --> 00:24:37,680
起来个兄弟替威尔

475
00:24:37,710 --> 00:24:39,630
CC c

476
00:24:39,900 --> 00:24:40,920
呃

477
00:24:40,925 --> 00:24:46,230
比韦维尔1=0那么这个一等于那个条件，这个就是一个永远是我们可以

478
00:24:46,235 --> 00:24:48,510
直接转账到4 ss型房地产

479
00:24:48,720 --> 00:24:50,640
这样就不需要放正好出去访

480
00:24:52,260 --> 00:24:54,360
这是一个逻辑化的历史，然后

481
00:24:54,660 --> 00:24:59,220
有楼梯进行楼梯化之后呢，我们会进行这个物流化就是

482
00:24:59,280 --> 00:25:01,050
考虑整个集训的数据分布

483
00:25:01,140 --> 00:25:03,660
然后来决定到底用哪一条

484
00:25:03,690 --> 00:25:07,260
打一个hi it，哪一个真正的物理算式？

485
00:25:07,500 --> 00:25:09,600
来去处理这条块

486
00:25:09,630 --> 00:25:10,860
他们这里面会

487
00:25:11,040 --> 00:25:13,440
去参考这个统计师

488
00:25:13,710 --> 00:25:14,760
然后

489
00:25:14,910 --> 00:25:19,230
然后来估算，每一条访问路径的成本

490
00:25:19,320 --> 00:25:20,730
然后生成物里计划

491
00:25:20,760 --> 00:25:22,980
然后再将这些物理计划

492
00:25:23,100 --> 00:25:25,830
扔给我们的扔到我们的这个分布式计算你

493
00:25:26,010 --> 00:25:30,000
比如说他在位置上，以及它的壁上的这个这个执行执行层

494
00:25:30,060 --> 00:25:31,170
然后进行执行

495
00:25:31,620 --> 00:25:33,990
然后这是我们整个这个税扣处理流程

496
00:25:34,590 --> 00:25:35,700
啊，这里举个例子

497
00:25:35,730 --> 00:25:39,540
我们到底是如何处理？比如说这两个简单的会说，也就是所

498
00:25:39,570 --> 00:25:44,190
就是算一个，为了条件在全部上所以外面条件，然后就计算抗体

499
00:25:44,670 --> 00:25:45,480
那么

500
00:25:46,710 --> 00:25:47,730
假设

501
00:25:48,390 --> 00:25:53,100
假设我这个这个这个条件没有索引，我可能需要全表扫描，那么

502
00:25:53,310 --> 00:25:56,460
首先，他利弊会根据我们的这个

503
00:25:56,640 --> 00:25:59,490
说这个表结构到py的编码规则

504
00:25:59,520 --> 00:26:03,600
达到到底哪些数据，哪些相关数据存在哪些节点上？

505
00:26:03,900 --> 00:26:05,040
只要在家

506
00:26:05,130 --> 00:26:06,300
这样一些

507
00:26:06,960 --> 00:26:08,130
就是条件

508
00:26:08,280 --> 00:26:09,420
以及抗的

509
00:26:09,425 --> 00:26:11,640
这这些聚合的表达式

510
00:26:11,700 --> 00:26:12,810
下垂到

511
00:26:13,560 --> 00:26:15,720
数据所设计那些节点上

512
00:26:15,780 --> 00:26:17,190
然后这些几点在？

513
00:26:17,400 --> 00:26:19,920
将数据从本地拿出来进行计算

514
00:26:20,010 --> 00:26:21,930
计算完之后呢，只需要

515
00:26:22,050 --> 00:26:22,740
奖

516
00:26:22,830 --> 00:26:26,580
最终的结果反馈给这个这个这个我们的结构引擎这块

517
00:26:26,585 --> 00:26:30,210
这个岁数已经会进行数据的汇总，那么这里这个例子中就

518
00:26:30,215 --> 00:26:31,530
每一个椎枕

519
00:26:31,800 --> 00:26:33,120
涉及到这个数据准确

520
00:26:33,270 --> 00:26:35,520
经过把数据拿出来之后

521
00:26:35,700 --> 00:26:39,960
经过这个非洲车，如果能坐这个飞，有车就会把它的基础上加一

522
00:26:39,990 --> 00:26:41,400
然后那么这样每个节点

523
00:26:41,520 --> 00:26:43,050
向上返回一个

524
00:26:43,110 --> 00:26:44,370
本地的烫头

525
00:26:44,580 --> 00:26:47,910
然后在最终这个他的币只有这个眼睛里会把他上不起来

526
00:26:47,915 --> 00:26:49,260
就能得到最终的结果

527
00:26:50,130 --> 00:26:51,690
所以这是一个比较简单的例

528
00:26:52,590 --> 00:26:57,900
然后另外呢，因为他就必须要处理海量数据，那么其实很多的我们的物理算子都是变形

529
00:26:57,905 --> 00:27:03,210
数量大的时候，我们利用单机多核的优势，能够很明显的加速数据的这个

530
00:27:03,810 --> 00:27:04,860
这个这个计算

531
00:27:05,130 --> 00:27:10,440
比如说我们的这样一个简单的例子来说，我们可能有一个重要的下面一

532
00:27:10,445 --> 00:27:13,020
一边是进行全面扫，一边读，所以

533
00:27:13,350 --> 00:27:15,330
那么，然后再进行一个还是？

534
00:27:15,540 --> 00:27:16,230
那么

535
00:27:16,620 --> 00:27:20,250
我们的无论是这个泰国，大概就是扫扫表

536
00:27:20,310 --> 00:27:21,570
你那是干

537
00:27:21,810 --> 00:27:24,930
所所以你这样两个算子都是并行的，我们会写多线程

538
00:27:25,110 --> 00:27:28,830
去太和上去拿出去去做一些计算下推

539
00:27:29,100 --> 00:27:31,830
然后拿到计算结果之后呢？再认为我们作文

540
00:27:32,070 --> 00:27:37,380
在中国算子这块，我们也我们的中文算法也是也是并行，我们会启动多个现场来

541
00:27:37,385 --> 00:27:40,230
同时，做作业，因为可能你数量比较大的时候

542
00:27:40,470 --> 00:27:45,780
这个需要计算计算的工作量是非常大的，所以通过多现场通过单机的多现场我们的明

543
00:27:45,785 --> 00:27:47,670
正在加速整个计算流程

544
00:27:48,000 --> 00:27:48,600
OK了

545
00:27:52,080 --> 00:27:53,910
对然后嗯

546
00:27:54,000 --> 00:27:55,740
所以，分布式户来说

547
00:27:55,745 --> 00:27:58,230
坐坐地铁哦哦

548
00:27:58,290 --> 00:28:01,110
是一个比较挑战的事情，为什么因为？

549
00:28:01,620 --> 00:28:06,930
假设大家想一下，我们通过所有的方式去给一个大的表示很超大表去加

550
00:28:06,935 --> 00:28:09,300
他一定或者加一个，所以

551
00:28:09,360 --> 00:28:11,250
那么，线上业务整个就会停滞

552
00:28:11,310 --> 00:28:13,440
而且这个表越大的竞争越越长

553
00:28:13,950 --> 00:28:15,870
所以我们一个和我们一个班

554
00:28:15,900 --> 00:28:20,280
一个解决的最核心问题就是如何能够不影响线上业务情况下

555
00:28:20,285 --> 00:28:22,320
在这样一个分布数据库上进行

556
00:28:23,040 --> 00:28:24,330
这个情况变更

557
00:28:24,750 --> 00:28:29,280
然后我们的整个算法是受这个不管饭的这个词不是用算法所启发

558
00:28:29,430 --> 00:28:32,370
然后我们整个是一个在线变更的算法也就

559
00:28:32,375 --> 00:28:33,900
任何弟弟要操作

560
00:28:34,140 --> 00:28:37,140
都不会手表都不会阻塞现象业务

561
00:28:37,260 --> 00:28:39,720
你可以先做，比如说你可以先加一列

562
00:28:39,840 --> 00:28:42,180
讲完讲完了之后，而且我们家裂损坏的

563
00:28:42,185 --> 00:28:43,560
家里的山里都非常快

564
00:28:43,770 --> 00:28:47,880
比如说你想上一个业务，需要一个新的索引，你可以先运行这个AI的那个

565
00:28:47,940 --> 00:28:49,200
所以你加完之后呢？

566
00:28:49,230 --> 00:28:51,060
然后你再把他给我更新上去

567
00:28:51,330 --> 00:28:54,030
所以我们整个人是不会不lock先生的业务

568
00:28:56,700 --> 00:29:02,010
对，然后后续的相关信息，大家可以去圩在这个网站上或这个

569
00:29:02,015 --> 00:29:03,720
后来我这个公众号儿

570
00:29:03,725 --> 00:29:05,490
或许记更多的信息

571
00:29:05,670 --> 00:29:06,720
好感谢大家

572
00:29:11,430 --> 00:29:12,030
我不知道

573
00:29:16,740 --> 00:29:17,340
我不知道

574
00:29:22,050 --> 00:29:22,650
我不知道

575
00:29:27,360 --> 00:29:27,960
我不知道

